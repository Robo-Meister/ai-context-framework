{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Documentation \u00b6 This project ships developer guides and design notes as static HTML and Markdown files. You can browse them directly from the repository or render them through MkDocs. Open dev/index.html for developer-focused documentation. Open theory/index.html for theoretical background and architecture notes. See event-context-standard.md for the event/context data model. Follow getting_started/quickstart.md for PyPI installation and pipeline examples. To serve the documentation locally, install the docs extra and run MkDocs: pip install caiengine[docs] mkdocs serve The site will be available at http://127.0.0.1:8000/ using the navigation from mkdocs.yml . Mass Testing \u00b6 Before going live, stress test the goal feedback loop and learning pipeline with synthetic data: pytest tests/test_goal_feedback_loop.py::test_goal_feedback_loop_randomized_batch \\ tests/test_feedback_pipeline.py::TestFeedbackPipeline::test_feedback_pipeline_randomized_batch These tests generate many fake context maps to ensure the system behaves correctly under load. Extend them as needed for your own scenarios.","title":"Documentation"},{"location":"index.html#documentation","text":"This project ships developer guides and design notes as static HTML and Markdown files. You can browse them directly from the repository or render them through MkDocs. Open dev/index.html for developer-focused documentation. Open theory/index.html for theoretical background and architecture notes. See event-context-standard.md for the event/context data model. Follow getting_started/quickstart.md for PyPI installation and pipeline examples. To serve the documentation locally, install the docs extra and run MkDocs: pip install caiengine[docs] mkdocs serve The site will be available at http://127.0.0.1:8000/ using the navigation from mkdocs.yml .","title":"Documentation"},{"location":"index.html#mass-testing","text":"Before going live, stress test the goal feedback loop and learning pipeline with synthetic data: pytest tests/test_goal_feedback_loop.py::test_goal_feedback_loop_randomized_batch \\ tests/test_feedback_pipeline.py::TestFeedbackPipeline::test_feedback_pipeline_randomized_batch These tests generate many fake context maps to ensure the system behaves correctly under load. Extend them as needed for your own scenarios.","title":"Mass Testing"},{"location":"event-context-standard.html","text":"Event Context Standard \u00b6 This document defines a standard structure for representing events with multi-layered context and trust metadata. Data model \u00b6 Event event_id : unique identifier timestamp : epoch seconds source : origin system or actor payload : raw message or data contexts : mapping of context categories ContextCategory name : category label such as user , device , or environment layers : ordered list of context layers ContextLayer layer_id : identifier within the category data : arbitrary JSON-compatible payload weight : relevance weighting (0.0\u20131.0) trust : confidence score (0.0\u20131.0) scope : optional scope such as global , session , or request parent : optional parent layer identifier Distribution \u00b6 Events and their context can be distributed as JSON documents. The structure is portable across languages and can be transported via message queues, HTTP APIs, or persisted to files. The default implementation uses JSON for ease of inspection and interoperability. Persistence API \u00b6 The module caiengine.common.context_model provides classes for the data model and helper functions for persistence: from caiengine.common import Event, ContextCategory, ContextLayer layer = ContextLayer(layer_id=\"session\", data={\"user\": \"abc\"}, weight=0.8) category = ContextCategory(name=\"user\", layers=[layer]) event = Event( event_id=\"evt-1\", timestamp=1710000000.0, source=\"sensor-A\", payload={\"action\": \"login\"}, contexts={\"user\": category}, ) # Save and load path = \"event.json\" event.save(path) loaded = Event.load(path) This API allows components to persist or transmit events with their associated context in a standardized format.","title":"Event Context Standard"},{"location":"event-context-standard.html#event-context-standard","text":"This document defines a standard structure for representing events with multi-layered context and trust metadata.","title":"Event Context Standard"},{"location":"event-context-standard.html#data-model","text":"Event event_id : unique identifier timestamp : epoch seconds source : origin system or actor payload : raw message or data contexts : mapping of context categories ContextCategory name : category label such as user , device , or environment layers : ordered list of context layers ContextLayer layer_id : identifier within the category data : arbitrary JSON-compatible payload weight : relevance weighting (0.0\u20131.0) trust : confidence score (0.0\u20131.0) scope : optional scope such as global , session , or request parent : optional parent layer identifier","title":"Data model"},{"location":"event-context-standard.html#distribution","text":"Events and their context can be distributed as JSON documents. The structure is portable across languages and can be transported via message queues, HTTP APIs, or persisted to files. The default implementation uses JSON for ease of inspection and interoperability.","title":"Distribution"},{"location":"event-context-standard.html#persistence-api","text":"The module caiengine.common.context_model provides classes for the data model and helper functions for persistence: from caiengine.common import Event, ContextCategory, ContextLayer layer = ContextLayer(layer_id=\"session\", data={\"user\": \"abc\"}, weight=0.8) category = ContextCategory(name=\"user\", layers=[layer]) event = Event( event_id=\"evt-1\", timestamp=1710000000.0, source=\"sensor-A\", payload={\"action\": \"login\"}, contexts={\"user\": category}, ) # Save and load path = \"event.json\" event.save(path) loaded = Event.load(path) This API allows components to persist or transmit events with their associated context in a standardized format.","title":"Persistence API"},{"location":"goal-driven-feedback-loop.html","text":"Goal-Driven Feedback Loop \u00b6 This document outlines the first steps in implementing a goal-driven feedback loop. 1. Clarify the Objective \u00b6 Define goals using the SMART framework: Specific \u2013 clearly state the outcome (e.g., \"increase monthly revenue\"). Measurable \u2013 identify metrics such as conversion rate, units sold, and average order value. Attainable \u2013 confirm targets are realistic given historical performance and resources. Relevant \u2013 ensure the goal aligns with broader organizational strategy. Time-bound \u2013 specify a timeframe or allow user-configurable limits. 2. Plan and Execute \u00b6 Break the goal into concrete actions or experiments. Prioritize tasks by expected impact and effort. Track execution with an event logger to correlate actions with outcomes. Persist the evolving history inside the feedback loop so repeated calls can use the latest context without resending the full timeline. 3. Gather Feedback \u00b6 Collect quantitative data such as key metrics, KPIs, and event logs. Capture qualitative input from users, stakeholders, or market trends. Store contextual factors (e.g., seasonality or campaigns) alongside results. 4. Analyze and Reflect \u00b6 Compare collected feedback against the defined objective and metrics. Identify patterns, anomalies, and root causes of success or shortfalls. Use historical context to distinguish action-driven effects from external trends. Surface lightweight analytics (gap, baseline, momentum) alongside suggested actions so downstream systems can quickly understand why a recommendation was made. 5. Adjust and Iterate \u00b6 Refine or reprioritize tactics based on analytical insights. Decide whether to continue, modify, or retire existing approaches. Loop back into planning with updated knowledge and context. 6. Document and Share \u00b6 Record goals, actions, outcomes, and lessons learned. Communicate insights to relevant teams and stakeholders. Maintain an archive to inform future goal-setting and execution. Roadmap Overview \u00b6 Clarify the objective. Plan and execute actions. Gather feedback. Analyze and reflect. Adjust and iterate. Document and share.","title":"Goal-driven Feedback Loop"},{"location":"goal-driven-feedback-loop.html#goal-driven-feedback-loop","text":"This document outlines the first steps in implementing a goal-driven feedback loop.","title":"Goal-Driven Feedback Loop"},{"location":"goal-driven-feedback-loop.html#1-clarify-the-objective","text":"Define goals using the SMART framework: Specific \u2013 clearly state the outcome (e.g., \"increase monthly revenue\"). Measurable \u2013 identify metrics such as conversion rate, units sold, and average order value. Attainable \u2013 confirm targets are realistic given historical performance and resources. Relevant \u2013 ensure the goal aligns with broader organizational strategy. Time-bound \u2013 specify a timeframe or allow user-configurable limits.","title":"1. Clarify the Objective"},{"location":"goal-driven-feedback-loop.html#2-plan-and-execute","text":"Break the goal into concrete actions or experiments. Prioritize tasks by expected impact and effort. Track execution with an event logger to correlate actions with outcomes. Persist the evolving history inside the feedback loop so repeated calls can use the latest context without resending the full timeline.","title":"2. Plan and Execute"},{"location":"goal-driven-feedback-loop.html#3-gather-feedback","text":"Collect quantitative data such as key metrics, KPIs, and event logs. Capture qualitative input from users, stakeholders, or market trends. Store contextual factors (e.g., seasonality or campaigns) alongside results.","title":"3. Gather Feedback"},{"location":"goal-driven-feedback-loop.html#4-analyze-and-reflect","text":"Compare collected feedback against the defined objective and metrics. Identify patterns, anomalies, and root causes of success or shortfalls. Use historical context to distinguish action-driven effects from external trends. Surface lightweight analytics (gap, baseline, momentum) alongside suggested actions so downstream systems can quickly understand why a recommendation was made.","title":"4. Analyze and Reflect"},{"location":"goal-driven-feedback-loop.html#5-adjust-and-iterate","text":"Refine or reprioritize tactics based on analytical insights. Decide whether to continue, modify, or retire existing approaches. Loop back into planning with updated knowledge and context.","title":"5. Adjust and Iterate"},{"location":"goal-driven-feedback-loop.html#6-document-and-share","text":"Record goals, actions, outcomes, and lessons learned. Communicate insights to relevant teams and stakeholders. Maintain an archive to inform future goal-setting and execution.","title":"6. Document and Share"},{"location":"goal-driven-feedback-loop.html#roadmap-overview","text":"Clarify the objective. Plan and execute actions. Gather feedback. Analyze and reflect. Adjust and iterate. Document and share.","title":"Roadmap Overview"},{"location":"svg_layered_generation.html","text":"Layered SVG Generation via Context-Aware Prompting \u00b6 This note explains how to extend the AI Context Framework so that text-generation sessions can also request layered SVG artwork that is easy to post-process. The overall idea is to treat every SVG asset as contextual knowledge, expose that knowledge inside prompts, and let the language model describe how to reuse and compose the pieces when new imagery is required. Asset Library Requirements \u00b6 To keep the generated artwork editable after the fact, organise the SVG library with the following conventions: Semantic Grouping \u2013 Store related shapes inside <g> elements whose id attributes are human-readable (e.g. hero_character/body ), so that the model can refer to them by name. Layer Metadata \u2013 Add JSON or YAML sidecar files that describe the visual purpose of each group (\"foreground character\", \"background gradient\", etc.). This metadata can be ingested alongside the raw SVG markup when building the context packet. Reusable Palette Tokens \u2013 Encode colours and gradients as CSS variables or named <defs> entries so that the model can remix palettes without editing literal hex codes. Fine-Grained Bounding Boxes \u2013 When possible, pre-compute simple bounding box coordinates for key elements and store them inside the metadata so that downstream tooling can reposition layers with minimal geometry work. Context Map Structure \u00b6 When you prepare a generation run, attach the SVG metadata to the context map under a dedicated channel (e.g. visual_assets ). Each entry should contain: A concise natural-language summary of the asset and its intended use. The path to the SVG file (or an inlined subset of its markup if the file is small). Optional references to palette tokens, font choices, and reusable backgrounds. During prompt construction, point the model to the relevant entries by name, and explain how the asset descriptions map to layers inside the final composition. Prompting Pattern \u00b6 In the task prompt, request the model to output a JSON (or another structured) plan that lists the layers to compose. For example: { \"canvas\": { \"width\": 1920, \"height\": 1080 }, \"layers\": [ { \"source\": \"characters/hero.svg#pose-1\", \"transform\": \"scale(1.1) translate(40, -20)\" }, { \"source\": \"backgrounds/cityscape.svg#layer-base\", \"opacity\": 0.85 }, { \"source\": \"effects/sun_glow.svg\", \"blend\": \"screen\" } ] } Because the model is operating on textual context, it will not rasterise the final artwork; instead, it will suggest which pre-existing SVG fragments to compose, along with any transformations. A thin automation layer can then apply these instructions with a deterministic SVG manipulation library (such as cairosvg , svgpathtools , or browser-side DOM APIs). Benefits \u00b6 Editability \u2013 Each layer remains an SVG group, so designers can tweak the shapes in vector tools without recreating the entire illustration. Consistency \u2013 Palettes, iconography, and proportions stay aligned with existing branding guidelines because all assets originate from a controlled library. Traceability \u2013 The prompt output doubles as a build manifest, making it easy to track which assets were combined and how they were transformed. Limitations and Mitigations \u00b6 Library Coverage \u2013 The approach only works if the asset library already contains suitable components. Fill gaps by commissioning new base assets or by adding a \"fallback\" layer type that can be generated on the fly. Prompt Budget \u2013 Large SVG files can exhaust context length. Use summaries and only expose the relevant fragments when constructing the context map. Geometric Precision \u2013 Free-form text instructions may need validation. Couple the generation step with lightweight rules or a post-processing script that verifies bounds and naming before committing the composed SVG. With these pieces in place, the framework can extend the same context-driven workflow it uses for text to orchestrate layered, editable SVG artwork. Example Asset Library \u00b6 For a concrete illustration of these conventions, see the sample library under docs/examples/svg_library . It contains characters, backgrounds, and effects SVGs grouped semantically, paired with JSON or YAML metadata that encodes summaries, palette tokens, and bounding boxes. The accompanying README shows how to translate the metadata into a context packet and a model-generated layer plan. Reference Pipeline \u00b6 The repository ships with a SvgLayerPipeline that automates the steps above. It gathers SVG metadata from any context provider, packages it into the visual_assets channel, asks an inference engine for a JSON plan, and post-processes the response so only resolvable layers remain. Bounding boxes defined in the metadata are merged into the final plan so downstream tooling can position fragments deterministically. See src/caiengine/pipelines/svg_layer_pipeline.py for the implementation and tests/test_svg_layer_pipeline.py for usage examples. Converting plans into layer actions \u00b6 Once a plan has been validated you can feed it into SvgActionPlanner to obtain an ordered list of explicit actions. Each entry is tagged as an add , transform , remove , or update command and includes the resolved asset fragment, bounding boxes, inline SVG payloads, and any requested transforms. This keeps the orchestration service focused on high-level intent while your SVG manipulation layer performs precise DOM edits or compositing work.\u3010F:src/caiengine/pipelines/svg_layer_actions.py\u2020L1-L247\u3011\u3010F:tests/test_svg_layer_actions.py\u2020L1-L123\u3011","title":"SVG Layered Generation"},{"location":"svg_layered_generation.html#layered-svg-generation-via-context-aware-prompting","text":"This note explains how to extend the AI Context Framework so that text-generation sessions can also request layered SVG artwork that is easy to post-process. The overall idea is to treat every SVG asset as contextual knowledge, expose that knowledge inside prompts, and let the language model describe how to reuse and compose the pieces when new imagery is required.","title":"Layered SVG Generation via Context-Aware Prompting"},{"location":"svg_layered_generation.html#asset-library-requirements","text":"To keep the generated artwork editable after the fact, organise the SVG library with the following conventions: Semantic Grouping \u2013 Store related shapes inside <g> elements whose id attributes are human-readable (e.g. hero_character/body ), so that the model can refer to them by name. Layer Metadata \u2013 Add JSON or YAML sidecar files that describe the visual purpose of each group (\"foreground character\", \"background gradient\", etc.). This metadata can be ingested alongside the raw SVG markup when building the context packet. Reusable Palette Tokens \u2013 Encode colours and gradients as CSS variables or named <defs> entries so that the model can remix palettes without editing literal hex codes. Fine-Grained Bounding Boxes \u2013 When possible, pre-compute simple bounding box coordinates for key elements and store them inside the metadata so that downstream tooling can reposition layers with minimal geometry work.","title":"Asset Library Requirements"},{"location":"svg_layered_generation.html#context-map-structure","text":"When you prepare a generation run, attach the SVG metadata to the context map under a dedicated channel (e.g. visual_assets ). Each entry should contain: A concise natural-language summary of the asset and its intended use. The path to the SVG file (or an inlined subset of its markup if the file is small). Optional references to palette tokens, font choices, and reusable backgrounds. During prompt construction, point the model to the relevant entries by name, and explain how the asset descriptions map to layers inside the final composition.","title":"Context Map Structure"},{"location":"svg_layered_generation.html#prompting-pattern","text":"In the task prompt, request the model to output a JSON (or another structured) plan that lists the layers to compose. For example: { \"canvas\": { \"width\": 1920, \"height\": 1080 }, \"layers\": [ { \"source\": \"characters/hero.svg#pose-1\", \"transform\": \"scale(1.1) translate(40, -20)\" }, { \"source\": \"backgrounds/cityscape.svg#layer-base\", \"opacity\": 0.85 }, { \"source\": \"effects/sun_glow.svg\", \"blend\": \"screen\" } ] } Because the model is operating on textual context, it will not rasterise the final artwork; instead, it will suggest which pre-existing SVG fragments to compose, along with any transformations. A thin automation layer can then apply these instructions with a deterministic SVG manipulation library (such as cairosvg , svgpathtools , or browser-side DOM APIs).","title":"Prompting Pattern"},{"location":"svg_layered_generation.html#benefits","text":"Editability \u2013 Each layer remains an SVG group, so designers can tweak the shapes in vector tools without recreating the entire illustration. Consistency \u2013 Palettes, iconography, and proportions stay aligned with existing branding guidelines because all assets originate from a controlled library. Traceability \u2013 The prompt output doubles as a build manifest, making it easy to track which assets were combined and how they were transformed.","title":"Benefits"},{"location":"svg_layered_generation.html#limitations-and-mitigations","text":"Library Coverage \u2013 The approach only works if the asset library already contains suitable components. Fill gaps by commissioning new base assets or by adding a \"fallback\" layer type that can be generated on the fly. Prompt Budget \u2013 Large SVG files can exhaust context length. Use summaries and only expose the relevant fragments when constructing the context map. Geometric Precision \u2013 Free-form text instructions may need validation. Couple the generation step with lightweight rules or a post-processing script that verifies bounds and naming before committing the composed SVG. With these pieces in place, the framework can extend the same context-driven workflow it uses for text to orchestrate layered, editable SVG artwork.","title":"Limitations and Mitigations"},{"location":"svg_layered_generation.html#example-asset-library","text":"For a concrete illustration of these conventions, see the sample library under docs/examples/svg_library . It contains characters, backgrounds, and effects SVGs grouped semantically, paired with JSON or YAML metadata that encodes summaries, palette tokens, and bounding boxes. The accompanying README shows how to translate the metadata into a context packet and a model-generated layer plan.","title":"Example Asset Library"},{"location":"svg_layered_generation.html#reference-pipeline","text":"The repository ships with a SvgLayerPipeline that automates the steps above. It gathers SVG metadata from any context provider, packages it into the visual_assets channel, asks an inference engine for a JSON plan, and post-processes the response so only resolvable layers remain. Bounding boxes defined in the metadata are merged into the final plan so downstream tooling can position fragments deterministically. See src/caiengine/pipelines/svg_layer_pipeline.py for the implementation and tests/test_svg_layer_pipeline.py for usage examples.","title":"Reference Pipeline"},{"location":"svg_layered_generation.html#converting-plans-into-layer-actions","text":"Once a plan has been validated you can feed it into SvgActionPlanner to obtain an ordered list of explicit actions. Each entry is tagged as an add , transform , remove , or update command and includes the resolved asset fragment, bounding boxes, inline SVG payloads, and any requested transforms. This keeps the orchestration service focused on high-level intent while your SVG manipulation layer performs precise DOM edits or compositing work.\u3010F:src/caiengine/pipelines/svg_layer_actions.py\u2020L1-L247\u3011\u3010F:tests/test_svg_layer_actions.py\u2020L1-L123\u3011","title":"Converting plans into layer actions"},{"location":"dev/TECHNICAL_ROADMAP.html","text":"\ud83d\udd2c Priority 4: Provider Abstractions & Expansion 9. KafkaContextProvider (Pub/Sub Support) \u00b6 \u2705 Read from Kafka topic, deserialize, store internally or forward to context engine \u2705 Publish ingested context and feedback via Kafka \ud83d\udd27 Why: Prepares ground for high-velocity, scalable deployments. \ud83d\udea7 Priority 5: Preparation for Extensibility & Learning 13. Data Standardizer for Robo Connector Workflows \u00b6 \u26d4\ufe0f Original integration likely dropped \u23f3 Provide JSON-based normalization of Robo Connector logs \ud83d\udd27 Why: Maintains compatibility with legacy flows without full integration 16. Packaging Improvements & PyPI Publishing \u00b6 \u23f3 Finalize module layout and import paths (see Phase 2 in Roadmap ) \u2705 Provide extras_require for optional dependencies \u23f3 Build and upload distribution artifacts to PyPI \ud83d\udd27 Why: Makes installation and distribution straightforward for users. 17. CI/CD Pipeline Integration \u00b6 \u23f3 Add GitHub Actions workflow for linting, tests and packaging \u23f3 Automate PyPI deployment on version tags (Phase 2 milestone) \ud83d\udd27 Why: Ensures consistent releases and quick feedback on pull requests. 18. Documentation Site & Community Tooling \u00b6 \u23f3 Publish a docs site with mkdocs or docsify (refer to Phase 5 in Roadmap ) \u23f3 Showcase examples and plugin discovery helpers \u23f3 Add issue and PR templates to grow community engagement \ud83d\udd27 Why: Phase 5 focuses on user adoption and community growth. Completed \u00b6 \ud83e\udd47 Priority 1: Core Debugging Infrastructure \u00b6 Context Inspector API \u2705 Basic API: list, fetch, filter by time, source, roles \u2705 Raw + filtered (Kalman-ready) context view \u2705 Support Redis first (extendable to others) \ud83d\udd27 Why: Base for UI, CLI tools, test harnesses, confidence checking. \ud83e\udd48 Priority 2: Vector/Embedding Analysis 2. Vector Comparison API + Diff Tools \u00b6 \u2705 Pairwise comparison (cosine, distance, trust-aware) \u2705 VectorCalculator & Filter fused API \u2705 Dump vectors to file or visualize drift \ud83d\udd27 Why: Helps track semantic matching, AI misfires, similarity thresholds. 3. Kalman Filter Integration \u00b6 \u2705 Add Kalman filter as optional layer in vector calculator \u2705 Flag in provider whether to use it \u2705 Dump raw vs filtered output for debug \ud83d\udd27 Why: Adds signal smoothing, suppresses noise in evolving context streams. 4. Vector Normalization Implementation \u00b6 \u2705 Normalize embeddings to unit vectors \u2705 Enforce consistent magnitude across providers \ud83d\udd27 Why: Ensures stable similarity calculations. \ud83e\udd49 Priority 3: Trust + Flow Debugging 5. Trust Calculation Trace \u00b6 \u2705 Output intermediate trust values \u2705 Identify influence of actor history, vector similarity, and metadata \u2705 Enable override for testing \ud83d\udd27 Why: Trust drift or anomalies are hard to diagnose without this. 6. Context Trigger Flow Tracing \u00b6 \u2705 Record \u201ccontext \u2192 matched rule \u2192 trigger fired\u201d \u2705 Capture matching similarity score \u2705 (Later) Tie to Robo Connector flow matching engine \ud83d\udd27 Why: Explains why something happened \u2014 a major ask in audits or validation. 7. Standardized Context Provider Interface \u00b6 \u2705 Formal interface (BaseContextProvider) \u2705 Existing RedisContextProvider refactored to implement it \u2705 Hooks for filtering and post-processing \ud83d\udd27 Why: Enables plug-in logic for Redis/Kafka/Static/Memory/etc. 8. Cache/MemoryContextProvider (In-Memory Only) \u00b6 \u2705 No Redis/Kafka dependency \u2705 Use for dev, testing, and minimal setups \u2705 Support filtering and similarity search \ud83d\udd27 Why: Reduces friction for newcomers and local testing. 10. Role Schema JSON Definition \u00b6 \u2705 Describe standard role fields and metadata \u2705 Publish example schema file \ud83d\udd27 Why: Provides consistent role handling across providers and tools. 11. Time-Decay & ANN Search Support \u00b6 \u2705 Apply time-decay weighting for older context \u2705 Integrate approximate nearest neighbor indexes \ud83d\udd27 Why: Improves relevance and speeds up context lookups. 12. Model Interface for Inference & Feedback \u00b6 \u2705 Abstract NN behind interface (e.g. ContextEncoderInterface) \u2705 Swap in local model, OpenAI, or any provider \u2705 (Later) Feedback hook: \u201cwas this match correct?\u201d \ud83d\udd27 Why: Critical to enable learning, personalization, or modular deployments. \ud83d\udd0c 14. Context Relay / ContextBus (Internal Mesh) \u00b6 \u2705 Accept context from multiple sources (Redis, Kafka, Memory, etc.) \u2705 Relay/mirror context to other nodes (via HTTP, gRPC, or message broker) \u2705 Optional: context filtering before relaying \ud83d\udcce Use cases: multi-node AI, real-time cooperation, mesh architecture \ud83d\udd27 Why: Enables distributed agents or Robo Assistants to share situational data in real-time. \ud83d\udccc Suggestion: Add to Priority 3 or 4, as it's foundational for scaling and very reusable. \ud83e\udde0 15. Network-Aware Context Hooks \u00b6 \u2705 Define external hooks/triggers based on context change \u2705 Push matched context (or diff) to other services \u2705 Allow action broadcasting / event chaining \ud83d\udd27 Why: Turns your system into a live graph of interconnected services \u2014 critical for Robo Assistant, swarm logic, and long-term Neuraflow. \ud83d\udccc Suggestion: Add to Priority 5, after filter + trigger tracing. 19. CLI for Manual Ingestion & Querying (Roadmap Phase 3 - Plugin & Provider Expansion) \u00b6 \u2705 Provide context add and context query commands \u2705 Works with any BaseContextProvider \ud83d\udd27 Why: Enables quick manual testing and debugging. 20. FileContextProvider (JSON) (Roadmap Phase 3 - Plugin & Provider Expansion) \u00b6 \u2705 Persist context entries to local JSON files \u2705 Useful for demos and offline experiments 21. SQLiteContextProvider (Roadmap Phase 3 - Plugin & Provider Expansion) \u00b6 \u2705 Lightweight SQL-backed provider for local storage \u2705 Reuse existing filter and query logic 21a. XMLContextProvider (Roadmap Phase 3 - Plugin & Provider Expansion) \u00b6 \u2705 Simple XML file persistence 21b. PostgresContextProvider (Roadmap Phase 3 - Plugin & Provider Expansion) \u00b6 \u2705 PostgreSQL-backed storage option 21c. MySQLContextProvider (Roadmap Phase 3 - Plugin & Provider Expansion) \u00b6 \u2705 MySQL-backed storage option 22. HTTPContextProvider (REST) (Roadmap Phase 3 - Plugin & Provider Expansion) \u00b6 \u2705 POST/GET endpoints for remote ingestion and retrieval \u2705 Bridge external services with context engine 23. Provider Pub/Sub & Broadcast Enhancements (Roadmap Phase 3 - Plugin & Provider Expansion) \u00b6 \u2705 Unified publish/subscribe hooks in BaseContextProvider \u2705 Broadcast context updates across providers \ud83d\udd27 Why: Completes subscription support in Phase 3. 24. Goal-Driven Feedback Loop \u00b6 \u2705 Basic loop with SimpleGoalFeedbackStrategy nudges actions toward a goal state \ud83d\udd27 Why: Enables proactive course correction toward desired states. \ud83d\udce6 Release & Community Infrastructure \u00b6 Packaging, automated publishing and a public documentation hub will make the project easier to consume and contribute to. The tasks above align with key roadmap phases: Phase 2: Stabilization & Distribution \u2013 lines 13\u201324 in Roadmap describe finalizing the package layout, publishing to PyPI and adding CI/CD workflows. Tasks 16 and 17 deliver these goals. Phase 5: Community & Growth \u2013 lines 40\u201346 in Roadmap cover launching a docs site and other community tooling. Task 18 implements this milestone.","title":"TECHNICAL ROADMAP"},{"location":"dev/TECHNICAL_ROADMAP.html#9-kafkacontextprovider-pubsub-support","text":"\u2705 Read from Kafka topic, deserialize, store internally or forward to context engine \u2705 Publish ingested context and feedback via Kafka \ud83d\udd27 Why: Prepares ground for high-velocity, scalable deployments. \ud83d\udea7 Priority 5: Preparation for Extensibility & Learning","title":"9. KafkaContextProvider (Pub/Sub Support)"},{"location":"dev/TECHNICAL_ROADMAP.html#13-data-standardizer-for-robo-connector-workflows","text":"\u26d4\ufe0f Original integration likely dropped \u23f3 Provide JSON-based normalization of Robo Connector logs \ud83d\udd27 Why: Maintains compatibility with legacy flows without full integration","title":"13. Data Standardizer for Robo Connector Workflows"},{"location":"dev/TECHNICAL_ROADMAP.html#16-packaging-improvements-pypi-publishing","text":"\u23f3 Finalize module layout and import paths (see Phase 2 in Roadmap ) \u2705 Provide extras_require for optional dependencies \u23f3 Build and upload distribution artifacts to PyPI \ud83d\udd27 Why: Makes installation and distribution straightforward for users.","title":"16. Packaging Improvements &amp; PyPI Publishing"},{"location":"dev/TECHNICAL_ROADMAP.html#17-cicd-pipeline-integration","text":"\u23f3 Add GitHub Actions workflow for linting, tests and packaging \u23f3 Automate PyPI deployment on version tags (Phase 2 milestone) \ud83d\udd27 Why: Ensures consistent releases and quick feedback on pull requests.","title":"17. CI/CD Pipeline Integration"},{"location":"dev/TECHNICAL_ROADMAP.html#18-documentation-site-community-tooling","text":"\u23f3 Publish a docs site with mkdocs or docsify (refer to Phase 5 in Roadmap ) \u23f3 Showcase examples and plugin discovery helpers \u23f3 Add issue and PR templates to grow community engagement \ud83d\udd27 Why: Phase 5 focuses on user adoption and community growth.","title":"18. Documentation Site &amp; Community Tooling"},{"location":"dev/TECHNICAL_ROADMAP.html#completed","text":"","title":"Completed"},{"location":"dev/TECHNICAL_ROADMAP.html#priority-1-core-debugging-infrastructure","text":"Context Inspector API \u2705 Basic API: list, fetch, filter by time, source, roles \u2705 Raw + filtered (Kalman-ready) context view \u2705 Support Redis first (extendable to others) \ud83d\udd27 Why: Base for UI, CLI tools, test harnesses, confidence checking. \ud83e\udd48 Priority 2: Vector/Embedding Analysis","title":"\ud83e\udd47 Priority 1: Core Debugging Infrastructure"},{"location":"dev/TECHNICAL_ROADMAP.html#2-vector-comparison-api-diff-tools","text":"\u2705 Pairwise comparison (cosine, distance, trust-aware) \u2705 VectorCalculator & Filter fused API \u2705 Dump vectors to file or visualize drift \ud83d\udd27 Why: Helps track semantic matching, AI misfires, similarity thresholds.","title":"2. Vector Comparison API + Diff Tools"},{"location":"dev/TECHNICAL_ROADMAP.html#3-kalman-filter-integration","text":"\u2705 Add Kalman filter as optional layer in vector calculator \u2705 Flag in provider whether to use it \u2705 Dump raw vs filtered output for debug \ud83d\udd27 Why: Adds signal smoothing, suppresses noise in evolving context streams.","title":"3. Kalman Filter Integration"},{"location":"dev/TECHNICAL_ROADMAP.html#4-vector-normalization-implementation","text":"\u2705 Normalize embeddings to unit vectors \u2705 Enforce consistent magnitude across providers \ud83d\udd27 Why: Ensures stable similarity calculations. \ud83e\udd49 Priority 3: Trust + Flow Debugging","title":"4. Vector Normalization Implementation"},{"location":"dev/TECHNICAL_ROADMAP.html#5-trust-calculation-trace","text":"\u2705 Output intermediate trust values \u2705 Identify influence of actor history, vector similarity, and metadata \u2705 Enable override for testing \ud83d\udd27 Why: Trust drift or anomalies are hard to diagnose without this.","title":"5. Trust Calculation Trace"},{"location":"dev/TECHNICAL_ROADMAP.html#6-context-trigger-flow-tracing","text":"\u2705 Record \u201ccontext \u2192 matched rule \u2192 trigger fired\u201d \u2705 Capture matching similarity score \u2705 (Later) Tie to Robo Connector flow matching engine \ud83d\udd27 Why: Explains why something happened \u2014 a major ask in audits or validation.","title":"6. Context Trigger Flow Tracing"},{"location":"dev/TECHNICAL_ROADMAP.html#7-standardized-context-provider-interface","text":"\u2705 Formal interface (BaseContextProvider) \u2705 Existing RedisContextProvider refactored to implement it \u2705 Hooks for filtering and post-processing \ud83d\udd27 Why: Enables plug-in logic for Redis/Kafka/Static/Memory/etc.","title":"7. Standardized Context Provider Interface"},{"location":"dev/TECHNICAL_ROADMAP.html#8-cachememorycontextprovider-in-memory-only","text":"\u2705 No Redis/Kafka dependency \u2705 Use for dev, testing, and minimal setups \u2705 Support filtering and similarity search \ud83d\udd27 Why: Reduces friction for newcomers and local testing.","title":"8. Cache/MemoryContextProvider (In-Memory Only)"},{"location":"dev/TECHNICAL_ROADMAP.html#10-role-schema-json-definition","text":"\u2705 Describe standard role fields and metadata \u2705 Publish example schema file \ud83d\udd27 Why: Provides consistent role handling across providers and tools.","title":"10. Role Schema JSON Definition"},{"location":"dev/TECHNICAL_ROADMAP.html#11-time-decay-ann-search-support","text":"\u2705 Apply time-decay weighting for older context \u2705 Integrate approximate nearest neighbor indexes \ud83d\udd27 Why: Improves relevance and speeds up context lookups.","title":"11. Time-Decay &amp; ANN Search Support"},{"location":"dev/TECHNICAL_ROADMAP.html#12-model-interface-for-inference-feedback","text":"\u2705 Abstract NN behind interface (e.g. ContextEncoderInterface) \u2705 Swap in local model, OpenAI, or any provider \u2705 (Later) Feedback hook: \u201cwas this match correct?\u201d \ud83d\udd27 Why: Critical to enable learning, personalization, or modular deployments.","title":"12. Model Interface for Inference &amp; Feedback"},{"location":"dev/TECHNICAL_ROADMAP.html#14-context-relay-contextbus-internal-mesh","text":"\u2705 Accept context from multiple sources (Redis, Kafka, Memory, etc.) \u2705 Relay/mirror context to other nodes (via HTTP, gRPC, or message broker) \u2705 Optional: context filtering before relaying \ud83d\udcce Use cases: multi-node AI, real-time cooperation, mesh architecture \ud83d\udd27 Why: Enables distributed agents or Robo Assistants to share situational data in real-time. \ud83d\udccc Suggestion: Add to Priority 3 or 4, as it's foundational for scaling and very reusable.","title":"\ud83d\udd0c 14. Context Relay / ContextBus (Internal Mesh)"},{"location":"dev/TECHNICAL_ROADMAP.html#15-network-aware-context-hooks","text":"\u2705 Define external hooks/triggers based on context change \u2705 Push matched context (or diff) to other services \u2705 Allow action broadcasting / event chaining \ud83d\udd27 Why: Turns your system into a live graph of interconnected services \u2014 critical for Robo Assistant, swarm logic, and long-term Neuraflow. \ud83d\udccc Suggestion: Add to Priority 5, after filter + trigger tracing.","title":"\ud83e\udde0 15. Network-Aware Context Hooks"},{"location":"dev/TECHNICAL_ROADMAP.html#19-cli-for-manual-ingestion-querying-roadmap-phase-3-plugin-provider-expansion","text":"\u2705 Provide context add and context query commands \u2705 Works with any BaseContextProvider \ud83d\udd27 Why: Enables quick manual testing and debugging.","title":"19. CLI for Manual Ingestion &amp; Querying (Roadmap Phase 3 - Plugin &amp; Provider Expansion)"},{"location":"dev/TECHNICAL_ROADMAP.html#20-filecontextprovider-json-roadmap-phase-3-plugin-provider-expansion","text":"\u2705 Persist context entries to local JSON files \u2705 Useful for demos and offline experiments","title":"20. FileContextProvider (JSON) (Roadmap Phase 3 - Plugin &amp; Provider Expansion)"},{"location":"dev/TECHNICAL_ROADMAP.html#21-sqlitecontextprovider-roadmap-phase-3-plugin-provider-expansion","text":"\u2705 Lightweight SQL-backed provider for local storage \u2705 Reuse existing filter and query logic","title":"21. SQLiteContextProvider (Roadmap Phase 3 - Plugin &amp; Provider Expansion)"},{"location":"dev/TECHNICAL_ROADMAP.html#21a-xmlcontextprovider-roadmap-phase-3-plugin-provider-expansion","text":"\u2705 Simple XML file persistence","title":"21a. XMLContextProvider (Roadmap Phase 3 - Plugin &amp; Provider Expansion)"},{"location":"dev/TECHNICAL_ROADMAP.html#21b-postgrescontextprovider-roadmap-phase-3-plugin-provider-expansion","text":"\u2705 PostgreSQL-backed storage option","title":"21b. PostgresContextProvider (Roadmap Phase 3 - Plugin &amp; Provider Expansion)"},{"location":"dev/TECHNICAL_ROADMAP.html#21c-mysqlcontextprovider-roadmap-phase-3-plugin-provider-expansion","text":"\u2705 MySQL-backed storage option","title":"21c. MySQLContextProvider (Roadmap Phase 3 - Plugin &amp; Provider Expansion)"},{"location":"dev/TECHNICAL_ROADMAP.html#22-httpcontextprovider-rest-roadmap-phase-3-plugin-provider-expansion","text":"\u2705 POST/GET endpoints for remote ingestion and retrieval \u2705 Bridge external services with context engine","title":"22. HTTPContextProvider (REST) (Roadmap Phase 3 - Plugin &amp; Provider Expansion)"},{"location":"dev/TECHNICAL_ROADMAP.html#23-provider-pubsub-broadcast-enhancements-roadmap-phase-3-plugin-provider-expansion","text":"\u2705 Unified publish/subscribe hooks in BaseContextProvider \u2705 Broadcast context updates across providers \ud83d\udd27 Why: Completes subscription support in Phase 3.","title":"23. Provider Pub/Sub &amp; Broadcast Enhancements (Roadmap Phase 3 - Plugin &amp; Provider Expansion)"},{"location":"dev/TECHNICAL_ROADMAP.html#24-goal-driven-feedback-loop","text":"\u2705 Basic loop with SimpleGoalFeedbackStrategy nudges actions toward a goal state \ud83d\udd27 Why: Enables proactive course correction toward desired states.","title":"24. Goal-Driven Feedback Loop"},{"location":"dev/TECHNICAL_ROADMAP.html#release-community-infrastructure","text":"Packaging, automated publishing and a public documentation hub will make the project easier to consume and contribute to. The tasks above align with key roadmap phases: Phase 2: Stabilization & Distribution \u2013 lines 13\u201324 in Roadmap describe finalizing the package layout, publishing to PyPI and adding CI/CD workflows. Tasks 16 and 17 deliver these goals. Phase 5: Community & Growth \u2013 lines 40\u201346 in Roadmap cover launching a docs site and other community tooling. Task 18 implements this milestone.","title":"\ud83d\udce6 Release &amp; Community Infrastructure"},{"location":"dev/api_reference.html","text":"API Reference \u00b6 This document outlines the stable public API surface of caiengine along with optional extras and experimental modules. The package now performs lazy loading of heavy components during attribute access, so importing caiengine keeps startup time low while still exposing the documented entry points. Stable top-level symbols \u00b6 Importing caiengine exposes the following stable objects via lazy loaders: CacheManager AIInferenceEngine ContextPipeline FeedbackPipeline QuestionPipeline PromptPipeline ConfigurablePipeline Fuser ContextManager DistributedContextManager ContextHookManager ContextHook MemoryContextProvider KafkaContextProvider * PolicyEvaluator export_onnx_bundle load_model_manifest model_manager NetworkManager SimpleNetworkMock ContextBus NodeRegistry ModelRegistry RedisPubSubChannel * KafkaPubSubChannel * NetworkInterface GoalDrivenFeedbackLoop SimpleGoalFeedbackStrategy PersonalityGoalFeedbackStrategy GoalFeedbackWorker GoalStateTracker SQLiteGoalStateBackend RedisGoalStateBackend * FeedbackEventBus CAIBridge FileModelRegistry cli __version__ is also available for compatibility. Items marked with * require optional extras that are described below. Optional extras \u00b6 Some components rely on third-party libraries that are not installed by default. Attempting to access the corresponding symbol will raise a helpful error unless the matching extra set is installed. Extra name Symbols kafka KafkaContextProvider , KafkaPubSubChannel redis RedisPubSubChannel , RedisGoalStateBackend Install extras with standard pip syntax, e.g. pip install caiengine[kafka] . Light-weight imports \u00b6 Setting the environment variable CAIENGINE_LIGHT_IMPORT restricts the package to exposing only __version__ and the cli module for minimal CLI-focused usage. All other attributes remain accessible through their module paths, e.g. from caiengine.pipelines import ContextPipeline . Experimental modules \u00b6 Experimental utilities have been moved under the caiengine.experimental namespace. They are not covered by the stability guarantees above and may change without notice. Current experimental exports include: caiengine.experimental.marketing_coach.AdaptiveCoach caiengine.experimental.marketing_coach.CoachingTip caiengine.experimental.goal_strategies.MarketingGoalFeedbackStrategy When importing caiengine these symbols are no longer re-exported at the top level, making their experimental status explicit. Goal state persistence backends \u00b6 GoalStateTracker accepts either a fully constructed backend instance or a configuration mapping describing how to build one. This makes it easy to wire the tracker using dependency injection containers or settings files. Example configuration loaded from application settings:: goal_state_backend = {\"type\": \"sqlite\", \"database\": \"/var/app/goal_state.db\"} tracker = GoalStateTracker(backend_config=goal_state_backend) To integrate with Redis, provide either a pre-configured client instance or a connection URL:: tracker = GoalStateTracker( backend_config={ \"type\": \"redis\", \"url\": \"redis://localhost:6379/0\", \"key\": \"myapp:goal_state\", } ) When using dependency injection frameworks, instantiate the backend externally and pass it directly:: backend = SQLiteGoalStateBackend(\"/var/app/goal_state.db\") tracker = GoalStateTracker(backend=backend)","title":"API Reference"},{"location":"dev/api_reference.html#api-reference","text":"This document outlines the stable public API surface of caiengine along with optional extras and experimental modules. The package now performs lazy loading of heavy components during attribute access, so importing caiengine keeps startup time low while still exposing the documented entry points.","title":"API Reference"},{"location":"dev/api_reference.html#stable-top-level-symbols","text":"Importing caiengine exposes the following stable objects via lazy loaders: CacheManager AIInferenceEngine ContextPipeline FeedbackPipeline QuestionPipeline PromptPipeline ConfigurablePipeline Fuser ContextManager DistributedContextManager ContextHookManager ContextHook MemoryContextProvider KafkaContextProvider * PolicyEvaluator export_onnx_bundle load_model_manifest model_manager NetworkManager SimpleNetworkMock ContextBus NodeRegistry ModelRegistry RedisPubSubChannel * KafkaPubSubChannel * NetworkInterface GoalDrivenFeedbackLoop SimpleGoalFeedbackStrategy PersonalityGoalFeedbackStrategy GoalFeedbackWorker GoalStateTracker SQLiteGoalStateBackend RedisGoalStateBackend * FeedbackEventBus CAIBridge FileModelRegistry cli __version__ is also available for compatibility. Items marked with * require optional extras that are described below.","title":"Stable top-level symbols"},{"location":"dev/api_reference.html#optional-extras","text":"Some components rely on third-party libraries that are not installed by default. Attempting to access the corresponding symbol will raise a helpful error unless the matching extra set is installed. Extra name Symbols kafka KafkaContextProvider , KafkaPubSubChannel redis RedisPubSubChannel , RedisGoalStateBackend Install extras with standard pip syntax, e.g. pip install caiengine[kafka] .","title":"Optional extras"},{"location":"dev/api_reference.html#light-weight-imports","text":"Setting the environment variable CAIENGINE_LIGHT_IMPORT restricts the package to exposing only __version__ and the cli module for minimal CLI-focused usage. All other attributes remain accessible through their module paths, e.g. from caiengine.pipelines import ContextPipeline .","title":"Light-weight imports"},{"location":"dev/api_reference.html#experimental-modules","text":"Experimental utilities have been moved under the caiengine.experimental namespace. They are not covered by the stability guarantees above and may change without notice. Current experimental exports include: caiengine.experimental.marketing_coach.AdaptiveCoach caiengine.experimental.marketing_coach.CoachingTip caiengine.experimental.goal_strategies.MarketingGoalFeedbackStrategy When importing caiengine these symbols are no longer re-exported at the top level, making their experimental status explicit.","title":"Experimental modules"},{"location":"dev/api_reference.html#goal-state-persistence-backends","text":"GoalStateTracker accepts either a fully constructed backend instance or a configuration mapping describing how to build one. This makes it easy to wire the tracker using dependency injection containers or settings files. Example configuration loaded from application settings:: goal_state_backend = {\"type\": \"sqlite\", \"database\": \"/var/app/goal_state.db\"} tracker = GoalStateTracker(backend_config=goal_state_backend) To integrate with Redis, provide either a pre-configured client instance or a connection URL:: tracker = GoalStateTracker( backend_config={ \"type\": \"redis\", \"url\": \"redis://localhost:6379/0\", \"key\": \"myapp:goal_state\", } ) When using dependency injection frameworks, instantiate the backend externally and pass it directly:: backend = SQLiteGoalStateBackend(\"/var/app/goal_state.db\") tracker = GoalStateTracker(backend=backend)","title":"Goal state persistence backends"},{"location":"dev/extending.html","text":"Extending CAIEngine \u00b6 The core architecture is intentionally modular so that you can introduce new context sources and goal-driven behaviours without rewriting pipelines. Review the diagrams in architecture.html and the class tables on the developer hub to understand how providers, feedback loops, and pipelines compose\u2014their relationships are reflected in those visuals. Build a custom context provider \u00b6 Context providers transform external data into ContextData objects and feed them into the pipelines. Existing implementations live under caiengine.providers and typically inherit from two helper classes: BaseContextProvider ( src/caiengine/providers/base_context_provider.py ) implements subscriber management and peer broadcasting. ContextProvider ( src/caiengine/interfaces/context_provider.py ) supplies trust-weight calculations so downstream modules can score the completeness of each context payload. Follow this checklist when creating your own provider: Inherit from BaseContextProvider . Add any optional mixins you need (e.g. extend ContextProvider when trust weighting is required). Map incoming records to ContextData . Construct instances from caiengine.objects.context_data.ContextData so the rest of the engine can reason about timestamps, confidence, roles, and situations uniformly. Expose ingestion hooks. Provide ingest_context / fetch_context methods that convert raw payloads into ContextData . Look at RedisContextProvider and KafkaContextProvider under src/caiengine/providers/ for examples of streaming integrations. Broadcast new context. Call self.publish_context(context_data) after each ingestion so subscribers (pipelines, distributed peers, audits) receive updates immediately. Register with helpers. If you want your provider to work with ConfigurablePipeline.from_dict , add it to the _PROVIDER_MAP in src/caiengine/pipelines/configurable_pipeline.py . Document required extras. If the provider needs third-party packages, declare them under [project.optional-dependencies] in pyproject.toml and mention the extra in the docs so users install it with pip install caiengine[extra] . Create a goal feedback strategy \u00b6 Goal strategies steer the GoalDrivenFeedbackLoop toward a desired state. The loop calls suggest_actions with a history of outcomes, the candidate actions returned by the pipeline, and the structured goal definition. Start from the GoalFeedbackStrategy interface ( src/caiengine/interfaces/goal_feedback_strategy.py ) and implement the suggest_actions method. Use the existing strategies for inspiration: SimpleGoalFeedbackStrategy ( src/caiengine/core/goal_strategies/simple_goal_strategy.py ) applies rule-based nudges by reading one_direction_layers weights. PersonalityGoalFeedbackStrategy ( src/caiengine/core/goal_strategies/personality_goal_strategy.py ) layers persona traits on top of the base heuristics. The experimental MarketingGoalFeedbackStrategy ( src/caiengine/experimental/goal_strategies/marketing_goal_strategy.py ) demonstrates a richer scoring model that tracks campaign metrics over time. When designing a new strategy: Define your goal schema. Decide which keys in the goal_state payload you require (e.g. tone, latency, risk scores) and document them. Normalise inputs. Ensure the history and action dictionaries are cleaned before comparison\u2014strategies often calculate averages or deltas. Return actionable feedback. Match the structure used by the pipelines: return a list aligned with the incoming current_actions , optionally adding fields such as confidence , next_step , or target_delta . Test with the loop. Instantiate GoalDrivenFeedbackLoop with your strategy and verify it works with the sample pipelines in docs/getting_started/quickstart.md . Link your strategy in the developer docs or README so users know which extra (if any) they must install. For complex behaviours you can also provide diagrams or state machines alongside the existing architecture visuals.","title":"Extending CAIEngine"},{"location":"dev/extending.html#extending-caiengine","text":"The core architecture is intentionally modular so that you can introduce new context sources and goal-driven behaviours without rewriting pipelines. Review the diagrams in architecture.html and the class tables on the developer hub to understand how providers, feedback loops, and pipelines compose\u2014their relationships are reflected in those visuals.","title":"Extending CAIEngine"},{"location":"dev/extending.html#build-a-custom-context-provider","text":"Context providers transform external data into ContextData objects and feed them into the pipelines. Existing implementations live under caiengine.providers and typically inherit from two helper classes: BaseContextProvider ( src/caiengine/providers/base_context_provider.py ) implements subscriber management and peer broadcasting. ContextProvider ( src/caiengine/interfaces/context_provider.py ) supplies trust-weight calculations so downstream modules can score the completeness of each context payload. Follow this checklist when creating your own provider: Inherit from BaseContextProvider . Add any optional mixins you need (e.g. extend ContextProvider when trust weighting is required). Map incoming records to ContextData . Construct instances from caiengine.objects.context_data.ContextData so the rest of the engine can reason about timestamps, confidence, roles, and situations uniformly. Expose ingestion hooks. Provide ingest_context / fetch_context methods that convert raw payloads into ContextData . Look at RedisContextProvider and KafkaContextProvider under src/caiengine/providers/ for examples of streaming integrations. Broadcast new context. Call self.publish_context(context_data) after each ingestion so subscribers (pipelines, distributed peers, audits) receive updates immediately. Register with helpers. If you want your provider to work with ConfigurablePipeline.from_dict , add it to the _PROVIDER_MAP in src/caiengine/pipelines/configurable_pipeline.py . Document required extras. If the provider needs third-party packages, declare them under [project.optional-dependencies] in pyproject.toml and mention the extra in the docs so users install it with pip install caiengine[extra] .","title":"Build a custom context provider"},{"location":"dev/extending.html#create-a-goal-feedback-strategy","text":"Goal strategies steer the GoalDrivenFeedbackLoop toward a desired state. The loop calls suggest_actions with a history of outcomes, the candidate actions returned by the pipeline, and the structured goal definition. Start from the GoalFeedbackStrategy interface ( src/caiengine/interfaces/goal_feedback_strategy.py ) and implement the suggest_actions method. Use the existing strategies for inspiration: SimpleGoalFeedbackStrategy ( src/caiengine/core/goal_strategies/simple_goal_strategy.py ) applies rule-based nudges by reading one_direction_layers weights. PersonalityGoalFeedbackStrategy ( src/caiengine/core/goal_strategies/personality_goal_strategy.py ) layers persona traits on top of the base heuristics. The experimental MarketingGoalFeedbackStrategy ( src/caiengine/experimental/goal_strategies/marketing_goal_strategy.py ) demonstrates a richer scoring model that tracks campaign metrics over time. When designing a new strategy: Define your goal schema. Decide which keys in the goal_state payload you require (e.g. tone, latency, risk scores) and document them. Normalise inputs. Ensure the history and action dictionaries are cleaned before comparison\u2014strategies often calculate averages or deltas. Return actionable feedback. Match the structure used by the pipelines: return a list aligned with the incoming current_actions , optionally adding fields such as confidence , next_step , or target_delta . Test with the loop. Instantiate GoalDrivenFeedbackLoop with your strategy and verify it works with the sample pipelines in docs/getting_started/quickstart.md . Link your strategy in the developer docs or README so users know which extra (if any) they must install. For complex behaviours you can also provide diagrams or state machines alongside the existing architecture visuals.","title":"Create a goal feedback strategy"},{"location":"dev/goal_feedback_loop.html","text":"Goal-Driven Feedback Loop \u00b6 Client applications often need to steer actions toward a target without pausing for user input. The goal-driven feedback loop can run as a lightweight background task to nudge progress quietly. Background Worker \u00b6 Run the loop inside a background worker, service worker, or scheduled task. The worker should periodically poll for new actions or subscribe to an event stream. Use the scaffold in GoalFeedbackWorker as a starting point. In production, back the accompanying GoalStateTracker with a durable backend such as SQLiteGoalStateBackend or RedisGoalStateBackend so restarts do not drop pending actions. The worker already emits structured log warnings when it falls back to the in-process poller or when the loop enters exponential backoff; wire those into your observability pipeline to surface stalled feedback processing quickly. State Tracking \u00b6 Persist the current goal state and any progress metrics in storage accessible by the worker (memory, local database, etc.). Update this state whenever goals change so the loop can compare new actions against the latest target. GoalDrivenFeedbackLoop now supports pluggable persistence providers. Pass a custom provider that implements GoalFeedbackPersistence when constructing the loop to persist the action history and calculated baselines into durable storage (e.g. SQLite, Redis, or a managed cache). The default provider keeps data in memory inside the current process. from caiengine.core.goal_feedback_loop import ( GoalDrivenFeedbackLoop, SQLiteGoalFeedbackPersistence, ) persistence = SQLiteGoalFeedbackPersistence(\"/var/lib/app/goal_feedback.db\") loop = GoalDrivenFeedbackLoop(strategy, goal_state=my_goal, persistence=persistence) Retention controls \u00b6 To prevent unbounded growth, configure retention parameters when creating the loop: retention_limit trims the stored history to the most recent N entries. retention_window discards entries older than the supplied duration (seconds or timedelta ). Both policies can be combined. After pruning, baselines automatically recalculate so that analytics continue to reflect the oldest retained datapoints. Event-Driven Updates \u00b6 When a new action appears, send it to the worker through a queue or message channel. The worker computes suggestions only when history or goal state changes, limiting needless work. FeedbackEventBus offers a minimal publish/subscribe interface. For higher throughput deployments attach AsyncFeedbackEventBus or adapt the GoalFeedbackWorker._handle_event callback to your message broker of choice so that goal and action updates arrive without relying on the periodic poller. Suggestion Logic \u00b6 Instantiate GoalDrivenFeedbackLoop with a strategy such as SimpleGoalFeedbackStrategy or PersonalityGoalFeedbackStrategy . Call suggest_actions with the current history and new actions to receive nudges toward the goal state. Example \u00b6 from time import sleep from caiengine.core.goal_feedback_loop import GoalDrivenFeedbackLoop from caiengine.core.goal_strategies import SimpleGoalFeedbackStrategy loop = GoalDrivenFeedbackLoop(SimpleGoalFeedbackStrategy(), goal_state={\"progress\": 10}) history: list[dict] = [] def worker(): while True: new_actions = fetch_new_actions() if new_actions: suggestion = loop.suggest_actions(history, new_actions) deliver(suggestion) history.extend(new_actions) sleep(5) This pattern keeps the loop running quietly in the background and only surfaces suggestions when the goal or action history changes.","title":"Goal-Driven Feedback Loop"},{"location":"dev/goal_feedback_loop.html#goal-driven-feedback-loop","text":"Client applications often need to steer actions toward a target without pausing for user input. The goal-driven feedback loop can run as a lightweight background task to nudge progress quietly.","title":"Goal-Driven Feedback Loop"},{"location":"dev/goal_feedback_loop.html#background-worker","text":"Run the loop inside a background worker, service worker, or scheduled task. The worker should periodically poll for new actions or subscribe to an event stream. Use the scaffold in GoalFeedbackWorker as a starting point. In production, back the accompanying GoalStateTracker with a durable backend such as SQLiteGoalStateBackend or RedisGoalStateBackend so restarts do not drop pending actions. The worker already emits structured log warnings when it falls back to the in-process poller or when the loop enters exponential backoff; wire those into your observability pipeline to surface stalled feedback processing quickly.","title":"Background Worker"},{"location":"dev/goal_feedback_loop.html#state-tracking","text":"Persist the current goal state and any progress metrics in storage accessible by the worker (memory, local database, etc.). Update this state whenever goals change so the loop can compare new actions against the latest target. GoalDrivenFeedbackLoop now supports pluggable persistence providers. Pass a custom provider that implements GoalFeedbackPersistence when constructing the loop to persist the action history and calculated baselines into durable storage (e.g. SQLite, Redis, or a managed cache). The default provider keeps data in memory inside the current process. from caiengine.core.goal_feedback_loop import ( GoalDrivenFeedbackLoop, SQLiteGoalFeedbackPersistence, ) persistence = SQLiteGoalFeedbackPersistence(\"/var/lib/app/goal_feedback.db\") loop = GoalDrivenFeedbackLoop(strategy, goal_state=my_goal, persistence=persistence)","title":"State Tracking"},{"location":"dev/goal_feedback_loop.html#retention-controls","text":"To prevent unbounded growth, configure retention parameters when creating the loop: retention_limit trims the stored history to the most recent N entries. retention_window discards entries older than the supplied duration (seconds or timedelta ). Both policies can be combined. After pruning, baselines automatically recalculate so that analytics continue to reflect the oldest retained datapoints.","title":"Retention controls"},{"location":"dev/goal_feedback_loop.html#event-driven-updates","text":"When a new action appears, send it to the worker through a queue or message channel. The worker computes suggestions only when history or goal state changes, limiting needless work. FeedbackEventBus offers a minimal publish/subscribe interface. For higher throughput deployments attach AsyncFeedbackEventBus or adapt the GoalFeedbackWorker._handle_event callback to your message broker of choice so that goal and action updates arrive without relying on the periodic poller.","title":"Event-Driven Updates"},{"location":"dev/goal_feedback_loop.html#suggestion-logic","text":"Instantiate GoalDrivenFeedbackLoop with a strategy such as SimpleGoalFeedbackStrategy or PersonalityGoalFeedbackStrategy . Call suggest_actions with the current history and new actions to receive nudges toward the goal state.","title":"Suggestion Logic"},{"location":"dev/goal_feedback_loop.html#example","text":"from time import sleep from caiengine.core.goal_feedback_loop import GoalDrivenFeedbackLoop from caiengine.core.goal_strategies import SimpleGoalFeedbackStrategy loop = GoalDrivenFeedbackLoop(SimpleGoalFeedbackStrategy(), goal_state={\"progress\": 10}) history: list[dict] = [] def worker(): while True: new_actions = fetch_new_actions() if new_actions: suggestion = loop.suggest_actions(history, new_actions) deliver(suggestion) history.extend(new_actions) sleep(5) This pattern keeps the loop running quietly in the background and only surfaces suggestions when the goal or action history changes.","title":"Example"},{"location":"dev/logging.html","text":"Logging and Observability \u00b6 The AI Context Framework standardises on Python's built-in logging module for all observability hooks. Workers and providers create named loggers using their fully-qualified module and class names so that deployments can selectively tune verbosity. Configuring Log Levels \u00b6 The framework does not install a global logging configuration. Downstream applications are expected to configure handlers and levels at process start-up, for example: import logging logging.basicConfig( level=\"INFO\", format=\"%(asctime)s %(name)s %(levelname)s %(message)s\", ) To increase verbosity for a specific component you can adjust its logger name. The goal feedback worker uses the logger name \"caiengine.core.goal_feedback_worker.GoalFeedbackWorker\" , while context providers follow the pattern \"<module>.<ClassName>\" . logging.getLogger(\"caiengine.core.goal_feedback_worker.GoalFeedbackWorker\").setLevel(\"DEBUG\") Structured Log Fields \u00b6 Critical log entries add structured fields via extra so that centralised log collectors can capture metadata (for example pending_actions , backoff_seconds , or subscriber_id ). When configuring formatters include the field names you care about, e.g. %(message)s pending=%(pending_actions)s , or use a JSON formatter to retain the structured attributes automatically. Goal Feedback Loop Diagnostics \u00b6 GoalFeedbackWorker escalates retries into exponential backoff while tagging every failure with attempt and backoff_seconds . A follow-up debug log then emits backoff_remaining while the worker sleeps. Configure your logging pipeline to alert when those fields remain high for several cycles\u2014this usually means the underlying provider keeps raising and the loop is stuck. GoalStateTracker and the storage backends also log when they fall back to in-memory persistence. Treat that warning as an operational smell in environments where resilience matters and override the backend with SQLite or Redis in production deployments. Provider Error Visibility \u00b6 Each context provider now emits structured errors if a subscriber callback crashes or if ingestion fails. The records include the subscriber_id , context_id , and backend-specific identifiers (for example, the SQLite database path). Attach handlers with filters that forward these errors to the same observability system as the rest of your application so that failed downstream consumers are visible without reproducing the issue locally. Token Usage Telemetry \u00b6 Inference engines wrapped by TokenUsageTracker now emit structured telemetry for every model invocation. Pipelines created through ConfigurablePipeline.from_dict automatically forward these events to the AuditLogger so downstream systems can observe prompt/completion token consumption per provider/category combination. Each audit record uses the token_usage step name and provides a payload similar to: { \"timestamp\": \"2024-05-12T10:15:32.123456\", \"operation\": \"predict\", \"provider\": \"memory\", \"category\": \"support\", \"usage\": { \"prompt_tokens\": 42, \"completion_tokens\": 13, \"total_tokens\": 55 } } Attach custom listeners to TokenUsageTracker.register_usage_listener if you need to ship the telemetry to additional observability sinks. Hooking into External Observability \u00b6 If you need to forward logs to an external sink, attach handlers to the relevant logger: handler = logging.StreamHandler() handler.setLevel(\"WARNING\") logging.getLogger(\"caiengine.providers.kafka_context_provider.KafkaContextProvider\").addHandler(handler) Handlers inherit levels from their parent logger hierarchy. Set propagate = False if you want to suppress duplicate entries once a custom handler is attached. Service Middleware Hooks \u00b6 CAIService now exposes its HTTP surface through FastAPI which makes it easy to insert cross-cutting concerns via middleware. Three lightweight middlewares are enabled out of the box and can be tuned when the service is constructed: Concern Configuration knob Notes Authentication auth_hook: Callable[[Request], Awaitable[AuthDecision] | AuthDecision] Hook receives the incoming Request and may return a Response , a dict payload, or False to reject the call. Error handling error_handler: Callable[[Exception, Request], Awaitable[Response | dict] | Response | dict] , include_error_details: bool Translate exceptions into custom JSON payloads or expose the original error message when include_error_details is set. Rate limiting rate_limit_per_minute: int , rate_limit_window_seconds: float , rate_limit_identifier: Callable[[Request], Awaitable[str] | str] Configure the number of allowed requests per window and optionally derive a custom identifier (for example from an API key). A limit of 0 disables the middleware. When running from the CLI the following flags surface the same controls: python -m caiengine.service --host 0.0.0.0 --port 8080 \\ --rate-limit 120 --rate-limit-window 60 \\ --include-error-details Applications embedding the service can also inspect metrics via the /usage endpoint which reports aggregated token counts from the goal feedback loop so that traffic shaping can be correlated with model consumption.","title":"Logging and Observability"},{"location":"dev/logging.html#logging-and-observability","text":"The AI Context Framework standardises on Python's built-in logging module for all observability hooks. Workers and providers create named loggers using their fully-qualified module and class names so that deployments can selectively tune verbosity.","title":"Logging and Observability"},{"location":"dev/logging.html#configuring-log-levels","text":"The framework does not install a global logging configuration. Downstream applications are expected to configure handlers and levels at process start-up, for example: import logging logging.basicConfig( level=\"INFO\", format=\"%(asctime)s %(name)s %(levelname)s %(message)s\", ) To increase verbosity for a specific component you can adjust its logger name. The goal feedback worker uses the logger name \"caiengine.core.goal_feedback_worker.GoalFeedbackWorker\" , while context providers follow the pattern \"<module>.<ClassName>\" . logging.getLogger(\"caiengine.core.goal_feedback_worker.GoalFeedbackWorker\").setLevel(\"DEBUG\")","title":"Configuring Log Levels"},{"location":"dev/logging.html#structured-log-fields","text":"Critical log entries add structured fields via extra so that centralised log collectors can capture metadata (for example pending_actions , backoff_seconds , or subscriber_id ). When configuring formatters include the field names you care about, e.g. %(message)s pending=%(pending_actions)s , or use a JSON formatter to retain the structured attributes automatically.","title":"Structured Log Fields"},{"location":"dev/logging.html#goal-feedback-loop-diagnostics","text":"GoalFeedbackWorker escalates retries into exponential backoff while tagging every failure with attempt and backoff_seconds . A follow-up debug log then emits backoff_remaining while the worker sleeps. Configure your logging pipeline to alert when those fields remain high for several cycles\u2014this usually means the underlying provider keeps raising and the loop is stuck. GoalStateTracker and the storage backends also log when they fall back to in-memory persistence. Treat that warning as an operational smell in environments where resilience matters and override the backend with SQLite or Redis in production deployments.","title":"Goal Feedback Loop Diagnostics"},{"location":"dev/logging.html#provider-error-visibility","text":"Each context provider now emits structured errors if a subscriber callback crashes or if ingestion fails. The records include the subscriber_id , context_id , and backend-specific identifiers (for example, the SQLite database path). Attach handlers with filters that forward these errors to the same observability system as the rest of your application so that failed downstream consumers are visible without reproducing the issue locally.","title":"Provider Error Visibility"},{"location":"dev/logging.html#token-usage-telemetry","text":"Inference engines wrapped by TokenUsageTracker now emit structured telemetry for every model invocation. Pipelines created through ConfigurablePipeline.from_dict automatically forward these events to the AuditLogger so downstream systems can observe prompt/completion token consumption per provider/category combination. Each audit record uses the token_usage step name and provides a payload similar to: { \"timestamp\": \"2024-05-12T10:15:32.123456\", \"operation\": \"predict\", \"provider\": \"memory\", \"category\": \"support\", \"usage\": { \"prompt_tokens\": 42, \"completion_tokens\": 13, \"total_tokens\": 55 } } Attach custom listeners to TokenUsageTracker.register_usage_listener if you need to ship the telemetry to additional observability sinks.","title":"Token Usage Telemetry"},{"location":"dev/logging.html#hooking-into-external-observability","text":"If you need to forward logs to an external sink, attach handlers to the relevant logger: handler = logging.StreamHandler() handler.setLevel(\"WARNING\") logging.getLogger(\"caiengine.providers.kafka_context_provider.KafkaContextProvider\").addHandler(handler) Handlers inherit levels from their parent logger hierarchy. Set propagate = False if you want to suppress duplicate entries once a custom handler is attached.","title":"Hooking into External Observability"},{"location":"dev/logging.html#service-middleware-hooks","text":"CAIService now exposes its HTTP surface through FastAPI which makes it easy to insert cross-cutting concerns via middleware. Three lightweight middlewares are enabled out of the box and can be tuned when the service is constructed: Concern Configuration knob Notes Authentication auth_hook: Callable[[Request], Awaitable[AuthDecision] | AuthDecision] Hook receives the incoming Request and may return a Response , a dict payload, or False to reject the call. Error handling error_handler: Callable[[Exception, Request], Awaitable[Response | dict] | Response | dict] , include_error_details: bool Translate exceptions into custom JSON payloads or expose the original error message when include_error_details is set. Rate limiting rate_limit_per_minute: int , rate_limit_window_seconds: float , rate_limit_identifier: Callable[[Request], Awaitable[str] | str] Configure the number of allowed requests per window and optionally derive a custom identifier (for example from an API key). A limit of 0 disables the middleware. When running from the CLI the following flags surface the same controls: python -m caiengine.service --host 0.0.0.0 --port 8080 \\ --rate-limit 120 --rate-limit-window 60 \\ --include-error-details Applications embedding the service can also inspect metrics via the /usage endpoint which reports aggregated token counts from the goal feedback loop so that traffic shaping can be correlated with model consumption.","title":"Service Middleware Hooks"},{"location":"dev/model_storage_plan.html","text":"Model Storage & Registry Plan \u00b6 This document outlines the approach for Phase 6 of the project, delivering portable and context\u2011aware model bundles. 1. Standard Representation \u00b6 ONNX as the core model format for interoperability across runtimes. A companion manifest.yaml or manifest.toml captures metadata such as model name, version, training context, required preprocessing and postprocessing steps, dependencies, and license details. 2. Packaging \u00b6 Package model.onnx and the manifest in a single archive (ZIP or OCI artifact). Optionally use content\u2011addressed or hashed file names to support reproducibility. 3. Tooling \u00b6 Provide utilities to load, validate, and migrate bundles across environments. Include simple CLI helpers for exporting, importing, and verifying model compatibility with the manifest. 4. Registry Integration \u00b6 Adopt a predictable bundle layout so a future registry can index manifest fields for discovery. Support context\u2011aware search and retrieval based on metadata such as task, framework version, and required hardware. This plan establishes a portable \"ONNX + manifest\" standard, enabling consistent model management, transport, and discovery across the project.","title":"Model Storage &amp; Registry Plan"},{"location":"dev/model_storage_plan.html#model-storage-registry-plan","text":"This document outlines the approach for Phase 6 of the project, delivering portable and context\u2011aware model bundles.","title":"Model Storage &amp; Registry Plan"},{"location":"dev/model_storage_plan.html#1-standard-representation","text":"ONNX as the core model format for interoperability across runtimes. A companion manifest.yaml or manifest.toml captures metadata such as model name, version, training context, required preprocessing and postprocessing steps, dependencies, and license details.","title":"1. Standard Representation"},{"location":"dev/model_storage_plan.html#2-packaging","text":"Package model.onnx and the manifest in a single archive (ZIP or OCI artifact). Optionally use content\u2011addressed or hashed file names to support reproducibility.","title":"2. Packaging"},{"location":"dev/model_storage_plan.html#3-tooling","text":"Provide utilities to load, validate, and migrate bundles across environments. Include simple CLI helpers for exporting, importing, and verifying model compatibility with the manifest.","title":"3. Tooling"},{"location":"dev/model_storage_plan.html#4-registry-integration","text":"Adopt a predictable bundle layout so a future registry can index manifest fields for discovery. Support context\u2011aware search and retrieval based on metadata such as task, framework version, and required hardware. This plan establishes a portable \"ONNX + manifest\" standard, enabling consistent model management, transport, and discovery across the project.","title":"4. Registry Integration"},{"location":"dev/ocr_to_structured_data.html","text":"Integrating OCR Pipelines with CAIEngine \u00b6 This guide describes how to connect an existing OCR service that already produces plain text, document type predictions, and preliminary key/value candidates with CAIEngine so you can replace brittle regular-expression post-processing with the framework's context routing and inference hooks. 1. High-Level Flow \u00b6 Run OCR outside of CAIEngine. Use your OCR system to obtain (a) the raw text of each document and (b) any metadata it provides such as page segmentation, document type guesses, or candidate key/value pairs. Wrap OCR output in a ContextProvider . Create a provider class that yields ContextItem objects representing each document or logical section. Attach the OCR metadata to the context payload so downstream modules can use it for scoring and extraction. Apply CAIEngine's deduplication and categorization stages. Use the built-in Deduplicator and Categorizer modules to cluster content snippets and filter noise. You can feed your OCR type guess into the categorizer as an initial signal, while allowing the engine's embedding similarity and rules to refine the classification. Fuse signals into a clean record. Configure the Fuser to consolidate overlapping snippets (e.g., repeated headers) and to merge OCR metadata with context-based insights. Invoke an AIInferenceEngine . Implement an inference hook that maps the fused context into your structured schema (r\u00e9sum\u00e9, invoice, contract, etc.). This component can use LLM prompts, ML classifiers, or deterministic logic tailored to your domain. Export to your target format. After inference, serialize the structured data into the format your downstream systems expect (JSON, CSV, database rows, etc.). 2. Implementing the OCR Context Provider \u00b6 Create a provider class under src/caiengine/providers (or your preferred module) that reads OCR output (files, API responses, or database rows) and yields ContextItem instances. Include fields such as: raw_text : the OCR-extracted text. document_type_hint : the OCR service's predicted type (e.g., invoice, CV). spans : offsets or bounding boxes for each candidate field the OCR detected. confidence_scores : numeric confidence metrics from the OCR service. By keeping these signals inside the context, CAIEngine modules can incorporate confidence and structural hints rather than relying on regexes. 2.1 Use the Built-in OCRContextProvider \u00b6 The repository now ships with an OCRContextProvider that implements the pattern above. It accepts raw OCR text, optional display_text , confidence scores, and either OCRSpan objects or dictionaries describing bounding boxes. Each ingested document is stored in a ContextData record with the ocr_metadata field populated so downstream modules can access both the structured payload and the spatial metadata. If you already have OCR spans represented as dictionaries, pass them directly to ingest_ocr_document ; they will be normalised into strongly-typed OCRSpan instances. This simplifies integrating new OCR sources without rewriting your data mapping logic. 3. Smarter Categorization than Regex \u00b6 Instead of regular expressions, leverage the TextEmbeddingComparer plus your OCR metadata: Seed the categorizer with representative exemplars for each document type. Combine embedding similarity with the OCR-provided document_type_hint to boost accuracy (e.g., accept the OCR label only if similarity exceeds a threshold; otherwise fall back to the most similar exemplar). Store hard rules only for high-precision cues (e.g., specific tax identifiers) rather than broad regex heuristics. This hybrid approach reduces false positives and allows the categorizer to adapt as you feed more training data. 3.1 Extending the Categorizer for OCR Signals \u00b6 For tricky OCR documents\u2014such as those with mixed languages, tables embedded as images, or heavily rotated scans\u2014augment the categorizer with richer signals so it can disambiguate near-duplicate content: Create OCR-aware features. In your ContextItem payload, add fields that capture layout hints (page numbers, column indexes), language detection results, and OCR confidence scores. These features give the categorizer more than just text similarity when deciding among competing categories. Add metadata-based scorers. Implement a custom SimilarityScorer that rewards matches where the OCR metadata aligns with category expectations (e.g., invoices usually contain currency symbols; resumes reference job titles). Register this scorer alongside the default embedding comparer. Handle weak OCR predictions. When the OCR engine emits low-confidence labels, fall back to embedding similarity plus rule-based overrides. This prevents a noisy OCR guess from locking the item into the wrong category. Log ambiguous assignments. Track cases where the categorizer returns multiple candidates with close scores. Review these examples, tune your OCR pipeline (deskewing, contrast boosting), and add new exemplars to narrow the margin over time. By enriching the categorizer with OCR-specific metadata and feedback, you can support documents that would otherwise be misrouted by pure text similarity or regex heuristics. 3.2 Returning Structured OCR Fields with Spatial Context \u00b6 Meeting downstream OCR consumers\u2014such as invoice ingestion systems that expect values plus their on-page position\u2014typically requires augmenting the categorizer with a richer payload than just raw text. A practical recipe is: Preserve whitespace-aligned text. Instead of normalising all whitespace, keep the OCR provider's spacing so you can reconstruct columnar layouts (tables, totals blocks). Store both the raw text and a \"display\" version that pads each line with spaces to mirror the original grid. Your ContextItem.payload might expose {\"text\": raw_text, \"display_text\": formatted_text} . Attach geometric spans per candidate field. Include bounding boxes or character-offset ranges for key OCR detections (invoice number, line items, totals). For example, add {\"field\": \"invoice_number\", \"bbox\": [x1, y1, x2, y2]} entries. When the categorizer selects a document type, downstream inference can recover both the value and its location. Score against layout-aware prototypes. Seed each category with exemplar snippets that include structured hints (e.g., a JSON blob of expected fields and their spatial relationships). Implement a custom SimilarityScorer that rewards OCR items whose detected fields align with the exemplar schema\u2014helping distinguish invoices with line-item tables from quotes or purchase orders. Emit structured context for inference. After categorization, package the enriched OCR payload into the fused context so your AIInferenceEngine can format the final record. For invoices, the inference step can iterate over the line_items span list, reconstruct each row's text via the preserved spacing, and output an ordered table alongside header fields such as invoice number and totals. These additions let the categorizer maintain spatial fidelity while still benefiting from embedding similarity and metadata signals. 4. Structured Extraction via Inference Engines \u00b6 Inside your AIInferenceEngine implementation: Receive the fused context items plus OCR metadata. Prompt an LLM or run a classifier to extract fields such as totals, vendor names, employment dates, or contract clauses. Use the OCR spans /coordinates to map extracted values back to the original document for auditing or highlighting. Validate required fields (e.g., totals > 0, presence of currency) before finalizing the record. Because the inference layer works on cleaned, categorized context, it can focus on semantic extraction rather than compensating for noisy regex groupings. 5. Output Formatting and Feedback Loops \u00b6 After extraction, push the structured record to your downstream format. Capture feedback from users (corrections, approvals) and feed it into CAIEngine's goal feedback loop so the categorizer and inference prompts improve over time. By isolating OCR as a pre-processing step and letting CAIEngine handle context management, categorization, and inference, you can replace fragile regex logic with a modular pipeline that is easier to extend and maintain.","title":"Integrating OCR Pipelines with CAIEngine"},{"location":"dev/ocr_to_structured_data.html#integrating-ocr-pipelines-with-caiengine","text":"This guide describes how to connect an existing OCR service that already produces plain text, document type predictions, and preliminary key/value candidates with CAIEngine so you can replace brittle regular-expression post-processing with the framework's context routing and inference hooks.","title":"Integrating OCR Pipelines with CAIEngine"},{"location":"dev/ocr_to_structured_data.html#1-high-level-flow","text":"Run OCR outside of CAIEngine. Use your OCR system to obtain (a) the raw text of each document and (b) any metadata it provides such as page segmentation, document type guesses, or candidate key/value pairs. Wrap OCR output in a ContextProvider . Create a provider class that yields ContextItem objects representing each document or logical section. Attach the OCR metadata to the context payload so downstream modules can use it for scoring and extraction. Apply CAIEngine's deduplication and categorization stages. Use the built-in Deduplicator and Categorizer modules to cluster content snippets and filter noise. You can feed your OCR type guess into the categorizer as an initial signal, while allowing the engine's embedding similarity and rules to refine the classification. Fuse signals into a clean record. Configure the Fuser to consolidate overlapping snippets (e.g., repeated headers) and to merge OCR metadata with context-based insights. Invoke an AIInferenceEngine . Implement an inference hook that maps the fused context into your structured schema (r\u00e9sum\u00e9, invoice, contract, etc.). This component can use LLM prompts, ML classifiers, or deterministic logic tailored to your domain. Export to your target format. After inference, serialize the structured data into the format your downstream systems expect (JSON, CSV, database rows, etc.).","title":"1. High-Level Flow"},{"location":"dev/ocr_to_structured_data.html#2-implementing-the-ocr-context-provider","text":"Create a provider class under src/caiengine/providers (or your preferred module) that reads OCR output (files, API responses, or database rows) and yields ContextItem instances. Include fields such as: raw_text : the OCR-extracted text. document_type_hint : the OCR service's predicted type (e.g., invoice, CV). spans : offsets or bounding boxes for each candidate field the OCR detected. confidence_scores : numeric confidence metrics from the OCR service. By keeping these signals inside the context, CAIEngine modules can incorporate confidence and structural hints rather than relying on regexes.","title":"2. Implementing the OCR Context Provider"},{"location":"dev/ocr_to_structured_data.html#21-use-the-built-in-ocrcontextprovider","text":"The repository now ships with an OCRContextProvider that implements the pattern above. It accepts raw OCR text, optional display_text , confidence scores, and either OCRSpan objects or dictionaries describing bounding boxes. Each ingested document is stored in a ContextData record with the ocr_metadata field populated so downstream modules can access both the structured payload and the spatial metadata. If you already have OCR spans represented as dictionaries, pass them directly to ingest_ocr_document ; they will be normalised into strongly-typed OCRSpan instances. This simplifies integrating new OCR sources without rewriting your data mapping logic.","title":"2.1 Use the Built-in OCRContextProvider"},{"location":"dev/ocr_to_structured_data.html#3-smarter-categorization-than-regex","text":"Instead of regular expressions, leverage the TextEmbeddingComparer plus your OCR metadata: Seed the categorizer with representative exemplars for each document type. Combine embedding similarity with the OCR-provided document_type_hint to boost accuracy (e.g., accept the OCR label only if similarity exceeds a threshold; otherwise fall back to the most similar exemplar). Store hard rules only for high-precision cues (e.g., specific tax identifiers) rather than broad regex heuristics. This hybrid approach reduces false positives and allows the categorizer to adapt as you feed more training data.","title":"3. Smarter Categorization than Regex"},{"location":"dev/ocr_to_structured_data.html#31-extending-the-categorizer-for-ocr-signals","text":"For tricky OCR documents\u2014such as those with mixed languages, tables embedded as images, or heavily rotated scans\u2014augment the categorizer with richer signals so it can disambiguate near-duplicate content: Create OCR-aware features. In your ContextItem payload, add fields that capture layout hints (page numbers, column indexes), language detection results, and OCR confidence scores. These features give the categorizer more than just text similarity when deciding among competing categories. Add metadata-based scorers. Implement a custom SimilarityScorer that rewards matches where the OCR metadata aligns with category expectations (e.g., invoices usually contain currency symbols; resumes reference job titles). Register this scorer alongside the default embedding comparer. Handle weak OCR predictions. When the OCR engine emits low-confidence labels, fall back to embedding similarity plus rule-based overrides. This prevents a noisy OCR guess from locking the item into the wrong category. Log ambiguous assignments. Track cases where the categorizer returns multiple candidates with close scores. Review these examples, tune your OCR pipeline (deskewing, contrast boosting), and add new exemplars to narrow the margin over time. By enriching the categorizer with OCR-specific metadata and feedback, you can support documents that would otherwise be misrouted by pure text similarity or regex heuristics.","title":"3.1 Extending the Categorizer for OCR Signals"},{"location":"dev/ocr_to_structured_data.html#32-returning-structured-ocr-fields-with-spatial-context","text":"Meeting downstream OCR consumers\u2014such as invoice ingestion systems that expect values plus their on-page position\u2014typically requires augmenting the categorizer with a richer payload than just raw text. A practical recipe is: Preserve whitespace-aligned text. Instead of normalising all whitespace, keep the OCR provider's spacing so you can reconstruct columnar layouts (tables, totals blocks). Store both the raw text and a \"display\" version that pads each line with spaces to mirror the original grid. Your ContextItem.payload might expose {\"text\": raw_text, \"display_text\": formatted_text} . Attach geometric spans per candidate field. Include bounding boxes or character-offset ranges for key OCR detections (invoice number, line items, totals). For example, add {\"field\": \"invoice_number\", \"bbox\": [x1, y1, x2, y2]} entries. When the categorizer selects a document type, downstream inference can recover both the value and its location. Score against layout-aware prototypes. Seed each category with exemplar snippets that include structured hints (e.g., a JSON blob of expected fields and their spatial relationships). Implement a custom SimilarityScorer that rewards OCR items whose detected fields align with the exemplar schema\u2014helping distinguish invoices with line-item tables from quotes or purchase orders. Emit structured context for inference. After categorization, package the enriched OCR payload into the fused context so your AIInferenceEngine can format the final record. For invoices, the inference step can iterate over the line_items span list, reconstruct each row's text via the preserved spacing, and output an ordered table alongside header fields such as invoice number and totals. These additions let the categorizer maintain spatial fidelity while still benefiting from embedding similarity and metadata signals.","title":"3.2 Returning Structured OCR Fields with Spatial Context"},{"location":"dev/ocr_to_structured_data.html#4-structured-extraction-via-inference-engines","text":"Inside your AIInferenceEngine implementation: Receive the fused context items plus OCR metadata. Prompt an LLM or run a classifier to extract fields such as totals, vendor names, employment dates, or contract clauses. Use the OCR spans /coordinates to map extracted values back to the original document for auditing or highlighting. Validate required fields (e.g., totals > 0, presence of currency) before finalizing the record. Because the inference layer works on cleaned, categorized context, it can focus on semantic extraction rather than compensating for noisy regex groupings.","title":"4. Structured Extraction via Inference Engines"},{"location":"dev/ocr_to_structured_data.html#5-output-formatting-and-feedback-loops","text":"After extraction, push the structured record to your downstream format. Capture feedback from users (corrections, approvals) and feed it into CAIEngine's goal feedback loop so the categorizer and inference prompts improve over time. By isolating OCR as a pre-processing step and letting CAIEngine handle context management, categorization, and inference, you can replace fragile regex logic with a modular pipeline that is easier to extend and maintain.","title":"5. Output Formatting and Feedback Loops"},{"location":"dev/releasing.html","text":"Releasing caiengine \u00b6 This checklist outlines the steps required to publish a new release of the caiengine package. 1. Prepare the Release \u00b6 [ ] Update the version in pyproject.toml and setup.py . [ ] Document the changes in CHANGELOG.md under a new version heading. [ ] Ensure documentation updates are committed, especially if the release introduces new developer workflows. 2. Verify Code Quality \u00b6 [ ] Run the unit test suite ( pytest ) and linting tools used by the project. [ ] Regenerate any artifacts or documentation that depend on the code, if applicable. 3. Build Artifacts \u00b6 [ ] Clean the dist/ directory and run python -m build from the project root. [ ] Inspect the resulting source distribution and wheel to confirm provider modules, docs, and the CLI entry point are present. 4. Smoke-Test the Wheel \u00b6 [ ] Create a fresh virtual environment. [ ] Install the newly built wheel with pip install dist/*.whl . [ ] If the CLI relies on optional providers (e.g., torch-backed storage), install the extras with pip install 'dist/*.whl[ai]' . [ ] Run context --help to confirm the CLI entry point works once dependencies are satisfied. 5. Publish \u00b6 [ ] Upload artifacts with twine upload dist/* (or the organization-specific publishing command). [ ] Tag the release in version control and push the tag. [ ] Announce the release through the appropriate communication channels. Keeping a log of each release run helps future maintainers debug issues quickly.","title":"Releasing caiengine"},{"location":"dev/releasing.html#releasing-caiengine","text":"This checklist outlines the steps required to publish a new release of the caiengine package.","title":"Releasing caiengine"},{"location":"dev/releasing.html#1-prepare-the-release","text":"[ ] Update the version in pyproject.toml and setup.py . [ ] Document the changes in CHANGELOG.md under a new version heading. [ ] Ensure documentation updates are committed, especially if the release introduces new developer workflows.","title":"1. Prepare the Release"},{"location":"dev/releasing.html#2-verify-code-quality","text":"[ ] Run the unit test suite ( pytest ) and linting tools used by the project. [ ] Regenerate any artifacts or documentation that depend on the code, if applicable.","title":"2. Verify Code Quality"},{"location":"dev/releasing.html#3-build-artifacts","text":"[ ] Clean the dist/ directory and run python -m build from the project root. [ ] Inspect the resulting source distribution and wheel to confirm provider modules, docs, and the CLI entry point are present.","title":"3. Build Artifacts"},{"location":"dev/releasing.html#4-smoke-test-the-wheel","text":"[ ] Create a fresh virtual environment. [ ] Install the newly built wheel with pip install dist/*.whl . [ ] If the CLI relies on optional providers (e.g., torch-backed storage), install the extras with pip install 'dist/*.whl[ai]' . [ ] Run context --help to confirm the CLI entry point works once dependencies are satisfied.","title":"4. Smoke-Test the Wheel"},{"location":"dev/releasing.html#5-publish","text":"[ ] Upload artifacts with twine upload dist/* (or the organization-specific publishing command). [ ] Tag the release in version control and push the tag. [ ] Announce the release through the appropriate communication channels. Keeping a log of each release run helps future maintainers debug issues quickly.","title":"5. Publish"},{"location":"dev/setup_gap_analysis.html","text":"Setup Gap Analysis \u00b6 This note captures a quick review of the current CAIEngine implementation and highlights the most visible gaps that still need work before the \"context-aware automation\" goal described in the README feels production-ready. Current strengths \u00b6 The ConfigurablePipeline already assembles categorisation, deduplication, optional policy filtering, trust scoring, and a goal-feedback loop. The component wiring is clear and keeps hooks for analytics via the AuditLogger .\u3010F:src/caiengine/pipelines/configurable_pipeline.py\u2020L8-L107\u3011\u3010F:src/caiengine/common/audit_logger.py\u2020L1-L27\u3011 Goal-tracking primitives exist, including the reusable GoalDrivenFeedbackLoop and the simple nudging strategy. These already add lightweight analytics (trend, progress ratio) when suggestions are produced so downstream clients can show \"why\" a recommendation was made.\u3010F:src/caiengine/core/goal_feedback_loop.py\u2020L23-L144\u3011\u3010F:src/caiengine/core/goal_strategies/simple_goal_strategy.py\u2020L1-L32\u3011 The HTTP service exposes ingestion, retrieval, goal suggestions, and token usage accounting, giving us an end-to-end integration touchpoint for demos and tests.\u3010F:src/caiengine/service.py\u2020L1-L91\u3011\u3010F:src/caiengine/providers/http_context_provider.py\u2020L1-L91\u3011 Notable gaps against the setup goal \u00b6 Provider reach and persistence. ConfigurablePipeline can only build pipelines backed by in-memory or file/SQL-lite providers; the richer options already implemented in caiengine.providers (Redis, Kafka, Postgres, HTTP) are not wired into the factory map. That limits any multi-node or durable setup described in the README and Roadmap. Extend _PROVIDER_MAP so these storage and streaming backends are selectable from configuration.\u3010F:src/caiengine/pipelines/configurable_pipeline.py\u2020L10-L41\u3011\u3010F:src/caiengine/providers/ init .py\u2020L5-L33\u3011 HTTP surface area and resilience. The current HTTPContextProvider and CAIService run on Python's basic HTTPServer without auth, paging, error reporting, or lifecycle health checks. There is no rate limiting, retry guidance, or schema validation before data is written into memory. A thin ASGI/WSGI layer (FastAPI, Starlette) with request schemas would give us the production hardening implied in the setup goal.\u3010F:src/caiengine/service.py\u2020L1-L91\u3011\u3010F:src/caiengine/providers/http_context_provider.py\u2020L1-L91\u3011 Durable history for goal feedback. The goal loop keeps all history and baselines in RAM and resets them whenever the caller sends a non-empty history payload. There is no persistence or eviction policy, so any restart loses momentum tracking and long-running services risk unbounded growth. Persisting the history (e.g. via the provider or a lightweight store) and adding size/age limits would let the goal analytics survive restarts and scale beyond short demos.\u3010F:src/caiengine/core/goal_feedback_loop.py\u2020L32-L120\u3011 Token accounting visibility. TokenUsageTracker aggregates usage but the service only exposes a global counter. Pipelines never log usage through the audit logger, making it hard to align resource consumption with specific context batches. Surfacing usage events (e.g. audit records per call or provider attribution) would help keep costs transparent when orchestrating multiple models.\u3010F:src/caiengine/inference/token_usage_tracker.py\u2020L1-L51\u3011\u3010F:src/caiengine/pipelines/configurable_pipeline.py\u2020L89-L111\u3011 Cache policy hooks. The in-memory provider stores everything until a TTL expires, but ingestion never forwards caller-supplied TTL values and there is no pruning strategy for stale context. Wiring TTL through the HTTP interface and surfacing cache invalidation hooks would keep the context graph fresh in persistent deployments.\u3010F:src/caiengine/providers/http_context_provider.py\u2020L1-L91\u3011\u3010F:src/caiengine/providers/memory_context_provider.py\u2020L1-L55\u3011\u3010F:src/caiengine/core/cache_manager.py\u2020L1-L34\u3011 Suggested next steps \u00b6 Expand the pipeline factory to expose the full provider catalogue and create smoke tests that exercise at least one durable backend (SQLite/Redis). Replace the bespoke HTTP server with a framework that gives us structured validation, middleware, and async concurrency; document auth expectations in the API docs. Externalise goal-loop state (history + baselines) and add retention limits so analytics stay meaningful during long runs. Emit token-usage audit events per inference call and link them with the provider/category metadata already present in pipeline results. Thread TTL/retention hints through ingestion APIs and document recommended cache policies for different deployment tiers (demo vs production). These changes close the biggest gaps between the current codebase and the project's stated goal of reliable context-aware automation.","title":"Setup Gap Analysis"},{"location":"dev/setup_gap_analysis.html#setup-gap-analysis","text":"This note captures a quick review of the current CAIEngine implementation and highlights the most visible gaps that still need work before the \"context-aware automation\" goal described in the README feels production-ready.","title":"Setup Gap Analysis"},{"location":"dev/setup_gap_analysis.html#current-strengths","text":"The ConfigurablePipeline already assembles categorisation, deduplication, optional policy filtering, trust scoring, and a goal-feedback loop. The component wiring is clear and keeps hooks for analytics via the AuditLogger .\u3010F:src/caiengine/pipelines/configurable_pipeline.py\u2020L8-L107\u3011\u3010F:src/caiengine/common/audit_logger.py\u2020L1-L27\u3011 Goal-tracking primitives exist, including the reusable GoalDrivenFeedbackLoop and the simple nudging strategy. These already add lightweight analytics (trend, progress ratio) when suggestions are produced so downstream clients can show \"why\" a recommendation was made.\u3010F:src/caiengine/core/goal_feedback_loop.py\u2020L23-L144\u3011\u3010F:src/caiengine/core/goal_strategies/simple_goal_strategy.py\u2020L1-L32\u3011 The HTTP service exposes ingestion, retrieval, goal suggestions, and token usage accounting, giving us an end-to-end integration touchpoint for demos and tests.\u3010F:src/caiengine/service.py\u2020L1-L91\u3011\u3010F:src/caiengine/providers/http_context_provider.py\u2020L1-L91\u3011","title":"Current strengths"},{"location":"dev/setup_gap_analysis.html#notable-gaps-against-the-setup-goal","text":"Provider reach and persistence. ConfigurablePipeline can only build pipelines backed by in-memory or file/SQL-lite providers; the richer options already implemented in caiengine.providers (Redis, Kafka, Postgres, HTTP) are not wired into the factory map. That limits any multi-node or durable setup described in the README and Roadmap. Extend _PROVIDER_MAP so these storage and streaming backends are selectable from configuration.\u3010F:src/caiengine/pipelines/configurable_pipeline.py\u2020L10-L41\u3011\u3010F:src/caiengine/providers/ init .py\u2020L5-L33\u3011 HTTP surface area and resilience. The current HTTPContextProvider and CAIService run on Python's basic HTTPServer without auth, paging, error reporting, or lifecycle health checks. There is no rate limiting, retry guidance, or schema validation before data is written into memory. A thin ASGI/WSGI layer (FastAPI, Starlette) with request schemas would give us the production hardening implied in the setup goal.\u3010F:src/caiengine/service.py\u2020L1-L91\u3011\u3010F:src/caiengine/providers/http_context_provider.py\u2020L1-L91\u3011 Durable history for goal feedback. The goal loop keeps all history and baselines in RAM and resets them whenever the caller sends a non-empty history payload. There is no persistence or eviction policy, so any restart loses momentum tracking and long-running services risk unbounded growth. Persisting the history (e.g. via the provider or a lightweight store) and adding size/age limits would let the goal analytics survive restarts and scale beyond short demos.\u3010F:src/caiengine/core/goal_feedback_loop.py\u2020L32-L120\u3011 Token accounting visibility. TokenUsageTracker aggregates usage but the service only exposes a global counter. Pipelines never log usage through the audit logger, making it hard to align resource consumption with specific context batches. Surfacing usage events (e.g. audit records per call or provider attribution) would help keep costs transparent when orchestrating multiple models.\u3010F:src/caiengine/inference/token_usage_tracker.py\u2020L1-L51\u3011\u3010F:src/caiengine/pipelines/configurable_pipeline.py\u2020L89-L111\u3011 Cache policy hooks. The in-memory provider stores everything until a TTL expires, but ingestion never forwards caller-supplied TTL values and there is no pruning strategy for stale context. Wiring TTL through the HTTP interface and surfacing cache invalidation hooks would keep the context graph fresh in persistent deployments.\u3010F:src/caiengine/providers/http_context_provider.py\u2020L1-L91\u3011\u3010F:src/caiengine/providers/memory_context_provider.py\u2020L1-L55\u3011\u3010F:src/caiengine/core/cache_manager.py\u2020L1-L34\u3011","title":"Notable gaps against the setup goal"},{"location":"dev/setup_gap_analysis.html#suggested-next-steps","text":"Expand the pipeline factory to expose the full provider catalogue and create smoke tests that exercise at least one durable backend (SQLite/Redis). Replace the bespoke HTTP server with a framework that gives us structured validation, middleware, and async concurrency; document auth expectations in the API docs. Externalise goal-loop state (history + baselines) and add retention limits so analytics stay meaningful during long runs. Emit token-usage audit events per inference call and link them with the provider/category metadata already present in pipeline results. Thread TTL/retention hints through ingestion APIs and document recommended cache policies for different deployment tiers (demo vs production). These changes close the biggest gaps between the current codebase and the project's stated goal of reliable context-aware automation.","title":"Suggested next steps"},{"location":"examples/svg_library/index.html","text":"Structured SVG Library Example \u00b6 This directory demonstrates how to structure layered SVG assets so they can be referenced by the AI Context Framework during generation tasks. The examples follow the conventions described in docs/svg_layered_generation.md and provide a miniature library that pairs markup with machine-readable metadata. Directory Layout \u00b6 svg_library/ characters/ hero.svg hero.meta.json drone.svg drone.meta.json field_medic.svg field_medic.meta.json backgrounds/ cityscape.svg cityscape.meta.yaml forest_glade.svg forest_glade.meta.yaml desert_canyon.svg desert_canyon.meta.yaml effects/ sun_glow.svg sun_glow.meta.json energy_ring.svg energy_ring.meta.json signal_wave.svg signal_wave.meta.json Each SVG is organised into semantic <g> groups whose id attributes encode their role. Palette tokens are expressed as CSS variables or named gradients, so prompts can reference reusable colour schemes without editing raw hex values. The metadata sidecars summarise the visual intent of each group, record bounding box hints, and list any palettes or blend modes that downstream tools should apply. These files can be ingested into a context map under a visual_assets channel so the language model can plan compositions. The expanded library now covers nature and desert backdrops, multiple support characters, and layered energy effects so the prompting examples can show how to mix and match multiple styles. Sample Context Packet Entry \u00b6 { \"channel\": \"visual_assets\", \"asset\": \"characters/hero.svg\", \"summary\": \"Hero character with cape and emblem for foreground placement.\", \"groups\": [ { \"id\": \"hero_character/body\", \"role\": \"primary figure\" }, { \"id\": \"hero_character/cape\", \"role\": \"dynamic cape\" }, { \"id\": \"hero_character/emblem\", \"role\": \"accent\" } ], \"palette_tokens\": [\"--skin\", \"--cape\", \"--suit\", \"--accent\"], \"bounding_boxes\": { \"hero_character/body\": { \"x\": 70, \"y\": 60, \"width\": 60, \"height\": 100 } } } Example Layer Plan Output \u00b6 { \"canvas\": { \"width\": 1920, \"height\": 1080 }, \"layers\": [ { \"source\": \"backgrounds/cityscape.svg#cityscape/background\", \"zIndex\": 0 }, { \"source\": \"backgrounds/cityscape.svg#cityscape/buildings-back\", \"transform\": \"translate(0, 20)\", \"opacity\": 0.85 }, { \"source\": \"characters/hero.svg#hero_character/body\", \"transform\": \"translate(860, 420) scale(2.2)\" }, { \"source\": \"characters/hero.svg#hero_character/cape\", \"transform\": \"translate(840, 400) scale(2.2)\", \"blend\": \"normal\" }, { \"source\": \"effects/sun_glow.svg\", \"transform\": \"translate(760, 260) scale(3.2)\", \"blend\": \"screen\", \"opacity\": 0.9 } ] } This plan demonstrates how the metadata can guide the model to compose existing layers without rasterising new artwork.","title":"Structured SVG Library Example"},{"location":"examples/svg_library/index.html#structured-svg-library-example","text":"This directory demonstrates how to structure layered SVG assets so they can be referenced by the AI Context Framework during generation tasks. The examples follow the conventions described in docs/svg_layered_generation.md and provide a miniature library that pairs markup with machine-readable metadata.","title":"Structured SVG Library Example"},{"location":"examples/svg_library/index.html#directory-layout","text":"svg_library/ characters/ hero.svg hero.meta.json drone.svg drone.meta.json field_medic.svg field_medic.meta.json backgrounds/ cityscape.svg cityscape.meta.yaml forest_glade.svg forest_glade.meta.yaml desert_canyon.svg desert_canyon.meta.yaml effects/ sun_glow.svg sun_glow.meta.json energy_ring.svg energy_ring.meta.json signal_wave.svg signal_wave.meta.json Each SVG is organised into semantic <g> groups whose id attributes encode their role. Palette tokens are expressed as CSS variables or named gradients, so prompts can reference reusable colour schemes without editing raw hex values. The metadata sidecars summarise the visual intent of each group, record bounding box hints, and list any palettes or blend modes that downstream tools should apply. These files can be ingested into a context map under a visual_assets channel so the language model can plan compositions. The expanded library now covers nature and desert backdrops, multiple support characters, and layered energy effects so the prompting examples can show how to mix and match multiple styles.","title":"Directory Layout"},{"location":"examples/svg_library/index.html#sample-context-packet-entry","text":"{ \"channel\": \"visual_assets\", \"asset\": \"characters/hero.svg\", \"summary\": \"Hero character with cape and emblem for foreground placement.\", \"groups\": [ { \"id\": \"hero_character/body\", \"role\": \"primary figure\" }, { \"id\": \"hero_character/cape\", \"role\": \"dynamic cape\" }, { \"id\": \"hero_character/emblem\", \"role\": \"accent\" } ], \"palette_tokens\": [\"--skin\", \"--cape\", \"--suit\", \"--accent\"], \"bounding_boxes\": { \"hero_character/body\": { \"x\": 70, \"y\": 60, \"width\": 60, \"height\": 100 } } }","title":"Sample Context Packet Entry"},{"location":"examples/svg_library/index.html#example-layer-plan-output","text":"{ \"canvas\": { \"width\": 1920, \"height\": 1080 }, \"layers\": [ { \"source\": \"backgrounds/cityscape.svg#cityscape/background\", \"zIndex\": 0 }, { \"source\": \"backgrounds/cityscape.svg#cityscape/buildings-back\", \"transform\": \"translate(0, 20)\", \"opacity\": 0.85 }, { \"source\": \"characters/hero.svg#hero_character/body\", \"transform\": \"translate(860, 420) scale(2.2)\" }, { \"source\": \"characters/hero.svg#hero_character/cape\", \"transform\": \"translate(840, 400) scale(2.2)\", \"blend\": \"normal\" }, { \"source\": \"effects/sun_glow.svg\", \"transform\": \"translate(760, 260) scale(3.2)\", \"blend\": \"screen\", \"opacity\": 0.9 } ] } This plan demonstrates how the metadata can guide the model to compose existing layers without rasterising new artwork.","title":"Example Layer Plan Output"},{"location":"getting_started/quickstart.html","text":"Quickstart \u00b6 Get started quickly with CAIEngine using the resources below: Live documentation: CAIEngine Docs Contribution guide: docs/dev/contributing.html This guide shows how to install CAIEngine from PyPI, enable the optional integrations, and run a minimal decision pipeline end-to-end. Install from PyPI \u00b6 CAIEngine is published as caiengine . Install the base package into a virtual environment: python -m venv .venv source .venv/bin/activate # Windows: .venv\\Scripts\\activate pip install --upgrade pip pip install caiengine The package exposes extras for common infrastructure. Combine them as needed: Extra Installs Use when you need redis redis Redis-backed context streaming and pub/sub fan-out. kafka kafka-python Kafka ingestion and feedback channels. storage mysql-connector-python , psycopg2-binary SQL persistence via MySQL or PostgreSQL providers. Install with pip\u2019s bracket syntax, for example: pip install caiengine[redis] # Multiple extras can be combined pip install caiengine[redis,kafka,storage] Configure optional providers \u00b6 Each provider accepts keyword arguments that mirror its constructor. The most common settings are shown below. Redis \u00b6 from caiengine.providers.redis_context_provider import RedisContextProvider provider = RedisContextProvider( redis_url=\"redis://localhost:6379/0\", key_prefix=\"context:\", ) The provider connects to the configured Redis instance, subscribes to the context:new channel, and publishes ingested updates to listeners. Kafka \u00b6 from caiengine.providers.kafka_context_provider import KafkaContextProvider provider = KafkaContextProvider( topic=\"context-events\", bootstrap_servers=\"kafka:9092\", group_id=\"cai-context\", publish_topic=\"context-out\", feedback_topic=\"context-feedback\", ) The Kafka provider consumes JSON payloads from topic , caches them in-memory, and (optionally) mirrors the processed context back to publish_topic or a separate feedback_topic for downstream workers. SQL storage \u00b6 Install the storage extra to use the relational providers: pip install caiengine[storage] Then point the pipeline at the matching provider class. For example, the PostgreSQL provider accepts a standard DSN string: from caiengine.providers.postgres_context_provider import PostgresContextProvider provider = PostgresContextProvider( dsn=\"postgresql://user:password@localhost:5432/caiengine\", ) MySQL and SQLite providers follow a similar pattern. See the module docstrings in caiengine.providers for the full argument lists. Run a decision pipeline \u00b6 The ConfigurablePipeline wraps context ingestion, policy filtering, trust scoring, and goal feedback in a single object. The snippet below loads a batch of context entries from memory, evaluates them with the simple policy, and asks the goal loop for suggestions. from caiengine.pipelines.configurable_pipeline import ConfigurablePipeline CONFIG = { \"provider\": {\"type\": \"memory\", \"args\": {}}, \"candidates\": [ {\"id\": \"workflow:triage\", \"priority\": 0.7}, {\"id\": \"workflow:escalate\", \"priority\": 0.3}, ], \"policy\": \"simple\", \"trust_weights\": {\"roles\": 0.6, \"situations\": 0.3, \"content\": 0.1}, \"feedback\": { \"type\": \"goal\", \"goal_state\": {\"response_time\": \"<5m\", \"customer_tone\": \"supportive\"}, \"one_direction_layers\": [\"response_time\"], }, } pipeline = ConfigurablePipeline.from_dict(CONFIG) batch = [ { \"id\": \"ticket-123\", \"roles\": [\"support\", \"customer\"], \"situations\": [\"priority:high\", \"tier:1\"], \"content\": \"Customer reported payment failure\", \"context\": {\"channel\": \"email\", \"attempts\": 2}, } ] results = pipeline.run(batch) for item in results: print(item) Running the script prints the categorised entry enriched with trust scores and goal_suggestion feedback. Replace the in-memory provider configuration with Redis, Kafka, or SQL options as your deployment requires. Provider configuration keys \u00b6 ConfigurablePipeline.from_dict accepts a short provider identifier and translates it to the underlying class from caiengine.providers . Key Provider class Notes memory MemoryContextProvider Ephemeral in-memory storage suitable for tests and demos. simple SimpleContextProvider Lightweight in-memory provider with peer broadcasting support. mock MockContextProvider Deterministic fixtures used by example pipelines. json / file FileContextProvider Persists context items to a local JSON file. xml XMLContextProvider Reads structured context data from XML files. csv CSVContextProvider Streams CSV rows as context entries. ocr OCRContextProvider Wraps OCR results with metadata preservation. http HTTPContextProvider Pulls context from HTTP/REST endpoints. redis RedisContextProvider Durable Redis-backed cache with pub/sub updates. kafka KafkaContextProvider Consumes and republishes context via Kafka topics. sqlite SQLiteContextProvider Local file-based SQL storage (uses SQLite). mysql MySQLContextProvider Connects to external MySQL-compatible databases. postgres PostgresContextProvider PostgreSQL connector (alias: postgresql ). All providers accept keyword arguments under provider.args that match their constructor signatures. Durable backends (Redis, Kafka, and the SQL options) require the corresponding optional extras to be installed.","title":"Quickstart"},{"location":"getting_started/quickstart.html#quickstart","text":"Get started quickly with CAIEngine using the resources below: Live documentation: CAIEngine Docs Contribution guide: docs/dev/contributing.html This guide shows how to install CAIEngine from PyPI, enable the optional integrations, and run a minimal decision pipeline end-to-end.","title":"Quickstart"},{"location":"getting_started/quickstart.html#install-from-pypi","text":"CAIEngine is published as caiengine . Install the base package into a virtual environment: python -m venv .venv source .venv/bin/activate # Windows: .venv\\Scripts\\activate pip install --upgrade pip pip install caiengine The package exposes extras for common infrastructure. Combine them as needed: Extra Installs Use when you need redis redis Redis-backed context streaming and pub/sub fan-out. kafka kafka-python Kafka ingestion and feedback channels. storage mysql-connector-python , psycopg2-binary SQL persistence via MySQL or PostgreSQL providers. Install with pip\u2019s bracket syntax, for example: pip install caiengine[redis] # Multiple extras can be combined pip install caiengine[redis,kafka,storage]","title":"Install from PyPI"},{"location":"getting_started/quickstart.html#configure-optional-providers","text":"Each provider accepts keyword arguments that mirror its constructor. The most common settings are shown below.","title":"Configure optional providers"},{"location":"getting_started/quickstart.html#redis","text":"from caiengine.providers.redis_context_provider import RedisContextProvider provider = RedisContextProvider( redis_url=\"redis://localhost:6379/0\", key_prefix=\"context:\", ) The provider connects to the configured Redis instance, subscribes to the context:new channel, and publishes ingested updates to listeners.","title":"Redis"},{"location":"getting_started/quickstart.html#kafka","text":"from caiengine.providers.kafka_context_provider import KafkaContextProvider provider = KafkaContextProvider( topic=\"context-events\", bootstrap_servers=\"kafka:9092\", group_id=\"cai-context\", publish_topic=\"context-out\", feedback_topic=\"context-feedback\", ) The Kafka provider consumes JSON payloads from topic , caches them in-memory, and (optionally) mirrors the processed context back to publish_topic or a separate feedback_topic for downstream workers.","title":"Kafka"},{"location":"getting_started/quickstart.html#sql-storage","text":"Install the storage extra to use the relational providers: pip install caiengine[storage] Then point the pipeline at the matching provider class. For example, the PostgreSQL provider accepts a standard DSN string: from caiengine.providers.postgres_context_provider import PostgresContextProvider provider = PostgresContextProvider( dsn=\"postgresql://user:password@localhost:5432/caiengine\", ) MySQL and SQLite providers follow a similar pattern. See the module docstrings in caiengine.providers for the full argument lists.","title":"SQL storage"},{"location":"getting_started/quickstart.html#run-a-decision-pipeline","text":"The ConfigurablePipeline wraps context ingestion, policy filtering, trust scoring, and goal feedback in a single object. The snippet below loads a batch of context entries from memory, evaluates them with the simple policy, and asks the goal loop for suggestions. from caiengine.pipelines.configurable_pipeline import ConfigurablePipeline CONFIG = { \"provider\": {\"type\": \"memory\", \"args\": {}}, \"candidates\": [ {\"id\": \"workflow:triage\", \"priority\": 0.7}, {\"id\": \"workflow:escalate\", \"priority\": 0.3}, ], \"policy\": \"simple\", \"trust_weights\": {\"roles\": 0.6, \"situations\": 0.3, \"content\": 0.1}, \"feedback\": { \"type\": \"goal\", \"goal_state\": {\"response_time\": \"<5m\", \"customer_tone\": \"supportive\"}, \"one_direction_layers\": [\"response_time\"], }, } pipeline = ConfigurablePipeline.from_dict(CONFIG) batch = [ { \"id\": \"ticket-123\", \"roles\": [\"support\", \"customer\"], \"situations\": [\"priority:high\", \"tier:1\"], \"content\": \"Customer reported payment failure\", \"context\": {\"channel\": \"email\", \"attempts\": 2}, } ] results = pipeline.run(batch) for item in results: print(item) Running the script prints the categorised entry enriched with trust scores and goal_suggestion feedback. Replace the in-memory provider configuration with Redis, Kafka, or SQL options as your deployment requires.","title":"Run a decision pipeline"},{"location":"getting_started/quickstart.html#provider-configuration-keys","text":"ConfigurablePipeline.from_dict accepts a short provider identifier and translates it to the underlying class from caiengine.providers . Key Provider class Notes memory MemoryContextProvider Ephemeral in-memory storage suitable for tests and demos. simple SimpleContextProvider Lightweight in-memory provider with peer broadcasting support. mock MockContextProvider Deterministic fixtures used by example pipelines. json / file FileContextProvider Persists context items to a local JSON file. xml XMLContextProvider Reads structured context data from XML files. csv CSVContextProvider Streams CSV rows as context entries. ocr OCRContextProvider Wraps OCR results with metadata preservation. http HTTPContextProvider Pulls context from HTTP/REST endpoints. redis RedisContextProvider Durable Redis-backed cache with pub/sub updates. kafka KafkaContextProvider Consumes and republishes context via Kafka topics. sqlite SQLiteContextProvider Local file-based SQL storage (uses SQLite). mysql MySQLContextProvider Connects to external MySQL-compatible databases. postgres PostgresContextProvider PostgreSQL connector (alias: postgresql ). All providers accept keyword arguments under provider.args that match their constructor signatures. Durable backends (Redis, Kafka, and the SQL options) require the corresponding optional extras to be installed.","title":"Provider configuration keys"},{"location":"status/layered_svg_progress.html","text":"Layered SVG Generation Progress \u00b6 This document summarises the current capabilities and remaining follow-up items for the layered SVG generation workflow driven by text prompts. Implemented \u00b6 Reference pipeline \u2013 SvgLayerPipeline orchestrates context collection, inference requests, and post-processing. It normalises incoming metadata into prompt-friendly packets, merges audit logging, and validates model output before returning a manifest for downstream tooling.\u3010F:src/caiengine/pipelines/svg_layer_pipeline.py\u2020L14-L205\u3011\u3010F:src/caiengine/pipelines/svg_layer_pipeline.py\u2020L206-L318\u3011 Validation safeguards \u2013 The pipeline verifies that each generated layer references a known asset fragment, attaches canonical fragment IDs, and enriches the response with bounding boxes and asset paths when available. Invalid references surface as warnings instead of hard failures.\u3010F:src/caiengine/pipelines/svg_layer_pipeline.py\u2020L206-L318\u3011 Action planning helper \u2013 SvgActionPlanner converts validated plans into explicit add/transform/remove commands, including layer metadata, bounding boxes, and inline SVG payloads so downstream services can perform precise edits.\u3010F:src/caiengine/pipelines/svg_layer_actions.py\u2020L1-L247\u3011\u3010F:tests/test_svg_layer_actions.py\u2020L1-L123\u3011 Unit coverage \u2013 tests/test_svg_layer_pipeline.py exercises asset normalisation, JSON-plan parsing, validation behaviour, and warning emission so regressions are caught in CI.\u3010F:tests/test_svg_layer_pipeline.py\u2020L1-L102\u3011 Usage guidance \u2013 docs/svg_layered_generation.md outlines asset library conventions, prompting patterns, and pipeline integration tips for layered outputs.\u3010F:docs/svg_layered_generation.md\u2020L1-L118\u3011 Next steps \u00b6 Expand automated tests to cover constraint handling, canvas overrides, and audit logging branches. Provide runnable examples that feed real SVG metadata through the pipeline and compose the resulting plan with an SVG manipulation library. Explore lightweight schema validation for context entries to catch malformed metadata before inference time.","title":"Layered SVG Generation Progress"},{"location":"status/layered_svg_progress.html#layered-svg-generation-progress","text":"This document summarises the current capabilities and remaining follow-up items for the layered SVG generation workflow driven by text prompts.","title":"Layered SVG Generation Progress"},{"location":"status/layered_svg_progress.html#implemented","text":"Reference pipeline \u2013 SvgLayerPipeline orchestrates context collection, inference requests, and post-processing. It normalises incoming metadata into prompt-friendly packets, merges audit logging, and validates model output before returning a manifest for downstream tooling.\u3010F:src/caiengine/pipelines/svg_layer_pipeline.py\u2020L14-L205\u3011\u3010F:src/caiengine/pipelines/svg_layer_pipeline.py\u2020L206-L318\u3011 Validation safeguards \u2013 The pipeline verifies that each generated layer references a known asset fragment, attaches canonical fragment IDs, and enriches the response with bounding boxes and asset paths when available. Invalid references surface as warnings instead of hard failures.\u3010F:src/caiengine/pipelines/svg_layer_pipeline.py\u2020L206-L318\u3011 Action planning helper \u2013 SvgActionPlanner converts validated plans into explicit add/transform/remove commands, including layer metadata, bounding boxes, and inline SVG payloads so downstream services can perform precise edits.\u3010F:src/caiengine/pipelines/svg_layer_actions.py\u2020L1-L247\u3011\u3010F:tests/test_svg_layer_actions.py\u2020L1-L123\u3011 Unit coverage \u2013 tests/test_svg_layer_pipeline.py exercises asset normalisation, JSON-plan parsing, validation behaviour, and warning emission so regressions are caught in CI.\u3010F:tests/test_svg_layer_pipeline.py\u2020L1-L102\u3011 Usage guidance \u2013 docs/svg_layered_generation.md outlines asset library conventions, prompting patterns, and pipeline integration tips for layered outputs.\u3010F:docs/svg_layered_generation.md\u2020L1-L118\u3011","title":"Implemented"},{"location":"status/layered_svg_progress.html#next-steps","text":"Expand automated tests to cover constraint handling, canvas overrides, and audit logging branches. Provide runnable examples that feed real SVG metadata through the pipeline and compose the resulting plan with an SVG manipulation library. Explore lightweight schema validation for context entries to catch malformed metadata before inference time.","title":"Next steps"}]}